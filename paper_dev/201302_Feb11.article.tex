%\documentclass[a4paper,10pt]{article}
\documentclass[journal]{IEEEtran}
%\documentclass[a4paper, 10pt, conference]{ieeeconf}

\usepackage{cite} %for citations
\usepackage{url}

 %this is for math typing (eg: cases)
\usepackage{amsmath}
   \usepackage{amsfonts}   % if you want the fonts
   \usepackage{amssymb}    % if you want extra symbols
\usepackage{epsfig} %for figures

\usepackage[center]{caption}%for captions
\usepackage[caption=false,font=footnotesize]{subfig} %for subfigures

%\nonstopmode

%opening
\title{
  Statistically Consistent Measures of Distance for POLSAR Data
%Scalar Homoskedastic Models for POLSAR data
}

%\author{Thanh-Hai Le, Ian McLoughlin}
\author{Thanh-Hai~Le,
        Ian~McLoughlin, 
	and Chan-Hua~Vun%
\thanks{Thanh-Hai~Le and Chan-Hua~Vun are with School of Computer Engineering, 
Nanyang Technological University, Singapore. Ian~McLoughlin is with School of Information Science and Technology,
University of Science and Technology of China.
}% <-this % stops a space
%\thanks{The authors wish to thank Dr. Ken-Yoong Lee and Dr. Timo Brestchneider of EADS Innovation-Works Singapore for 
%	their initial discussions and for providing us the RADAR-SAT2 imagery used in this paper. }% <-this % stops a space
\thanks{Manuscript received ?, 2013; revised ?.}}

\markboth{Transactions on Geoscience \& Remote Sensing,~Vol.~?, No.~?, ?~2013}%
{ Le \MakeLowercase{\textit{et al.}}:  Statistically Consistent Measures of Distance for POLSAR Data}

\begin{document}

\maketitle

\begin{abstract}
In this paper, a homoskedastic and additive model for polarimetric SAR (POLSAR) data is introduced. 
The statistical properties of this model subsequently lead to a few different consistent measures of distance for the POLSAR covariance matrix.
The dis-similarity measurements are initially developed for both partial (2x2) and full (3x3 monostatic case) polarimetric SAR data.
They are computed from the determinant of the POLSAR covariance matrix.
Interestingly, when the multi-polarization POLSAR is collapsed into the single-polarization SAR,
  this covariance matrix determinant is neatly transformed into the traditional SAR intensity.
Thus the SAR intensity statistics can now be considered as a special case of the theoretical model for POLSAR.
While powerful theoretically, the statistical model is also robust in handling practical data.
It can be validated and match reasonably well with practical data,
 even  when  the supposedly independent polarimetric components are actually highly correlated (e.g. between $S_{hh}$ and $S_{vv}$).
Moreover, the match can be further improved, as better match is shown achievable, 
  if the model validation process include an estimation of the dataset's Effective Number of Looks (ENL) 
  instead of blind employment of the look number given by the SAR processor.
Towards the end, the practical application of these dissimilarity measures is briefly demonstrated in the context of evaluating POLSAR speckle filters.  
\end{abstract}

\begin{IEEEkeywords}
Polarimetric, Synthetic aperture radar, speckle-filtering, homoskedasticity
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
%\section{POLSAR data: statistical analysis and logarithmic transformation}

In this paper, the POLSAR scattering vector is denoted as $s$.
In the case of partial polarimetric SAR (single polarization in transmit and dual polarization in receipt),
  the vector is two-dimensional ($d=2$) and is normally written as: 
\begin{equation}
s_{part}=\begin{bmatrix}
S_h\\ 
S_v
\end{bmatrix}
\end{equation}
In the case of full and monostatic POLSAR data,
  the vector is three-dimensional ($d=3$) and is presented as:
\begin{equation}
s_{full}=\begin{bmatrix}
S_{hh}\\
\sqrt{2}S_{hv}\\
S_{vv}
\end{bmatrix}
\end{equation}

Let $\Sigma=E [ss^{*T}]$ denotes the population expected value of the POLSAR covariance matrix,
  where $s^{*T}$ denotes the complex conjugate transpose of $s$. 
Assuming all the elements in $s$ are independent
  and $s$ is jointly circular complex Gaussian with the given covariance matrix $\Sigma$,
  then the probably density function (PDF) of $s$ can be written as:
\begin{equation}
  pdf(s;\Sigma)=\frac{1}{\pi^d|\Sigma|} e^{-s^{*T}\Sigma^{-1}s}
\end{equation}
where $|M|$ denotes the determinant of the matrix $M$.

As covariance matrix is only defined on multiple data points,
  sample covariance matrix of POLSAR data is commonly presented in ``ensemble'' format.
They are formed as the mean of Hermitian outer product of single-look scattering vectors
\begin{equation}
  C_v = \langle ss^{*T} \rangle = \frac{1}{L} \sum^L_{i=1}s_is_i^{*T}
\end{equation}
with $s_i$ denotes the single-look scattering vector,
  which equals $s_{part}$ in the case of partial POLSAR and
  $s_{full}$ in the case of full polarimetry,
and $L$ is the number of looks.

Complex Wishart distribution statistics, however, is normally written for the scaled covariance matrix
$Z=LC_v$, whose PDF is given as:
\begin{equation}
  pdf(Z;d,\Sigma,L)=\frac{|Z|^{L-d}}{|\Sigma^L|\Gamma_d(L)}e^{-tr(\Sigma^{-1}Z)}
\end{equation}
with $\Gamma_d(L) = \pi^{d(d-1)/2} \prod^{d-1}_{i=0}\Gamma(L-i)$
and $d$ is the dimensional number of the POLSAR covariance matrix.

Our approach differs by applying the homoskedastic log transformation
  on a less-than-well-known result for the deterimant of the covarinace matrix.
  %under the assumption of circular complex Gaussian distribution
  %applicable for POLSAR data.
In \cite{Goodman_1963_AMS_178}, %Goodman
it has been proven that the ratio between the observable and the expected values of the sample covariance matrix's determinants
  behaves like a product of $d$ chi-squared random variables with different degrees of freedom 
\begin{equation}
\chi^d_L = (2L)^d \frac{|C_v|}{|\Sigma_v|} \sim \prod_{i=0}^{d-1} \chi^2 (2L-2i)
\label{eqn:prod_chi_squared_rv}  
\end{equation}

Its log-transformed variable consequently 
  behaves like a summation of $d$ log-chi-squared random variables with the same degrees of freedom  
\begin{equation}
\Lambda^d_L = ln \left[ (2L)^d \frac{|C_v|}{|\Sigma_v|} \right] \sim \sum_{i=0}^{d-1} \Lambda^\chi (2L-2i)
\label{eqn:sum_log_chi_squared_rv}
\end{equation}
with
  $\Lambda^\chi (k) \sim \ln \left[ \chi^2 (k) \right]$

In this paper, the above results are further explored in the context of POLSAR data processing
  and a few scalar, consistent and homoskedastic measures of distance is proposed.
The paper is structured as follows:
  after the preceding introduction to the basics of POLSAR statiscal analysis,
  the second section presents conclusive evidence for two related points.
The first is that: POLSAR data is multiplicative and heteroskedastic in its original domain.
And the second: log-transformation converts it into an additive and homoskedastic model.
Consequently a few consistent measures of distance are presented in section \ref{sec:distance_measure}.
After the model is validated against both partial and full polarimetric SAR data in Section \ref{sec:polsar_models_validation},
  section \ref{sec:sar_special_case_of_polsar} discusses
    how the proposed models for the multi-variate POLSAR can be used to derive the well-known models for the univariate SAR data as its special case.
Besides being theoretically powerful, 
  the model is shown, in section \ref{sec:improve_the_match_bw_theory_practice}, to be robust in handling a few practical imperfections that violate conventional assumptions. 
As an example application of the consistent and homoskedastic dis-similarity measures, 
  section \ref{sec:evaluating_polsar_filters} explores how they can be used in evaluating POLSAR speckle filters.   
Finally, section \ref{sec:discussion_conclusion} critically reviews related works in literature 
  before providing some conclusional discussion. 

\section{Original Hetoroskedastic Domain and the Homoskedastic Log-Transformation}
\label{sec:polsar_heterosked_model_and_log_transform}

In this section the multiplicative nature of POLSAR data is illustrated.
Log-transformation is shown converting this into a more familiar additive model.
Heteroskedasticity, which is defined as the dependence of variance upon the underlying signal,
  is proved to be the case for the original POLSAR data.
In log-transformed domain, the case for a homoskedastic model,
  where sample variance is fixed and thus independent of the underlying signal,
  is demonstrated.
To keep the section flowing, the mathematical derivation is only presented here in major sketches.
For more detailed derivation, Appendix \ref{chap:appendix_a} is to be reviewed.

From Eqn. \ref{eqn:prod_chi_squared_rv} and Eqn. \ref{eqn:sum_log_chi_squared_rv}
we have:
\begin{eqnarray}
  |C_v| &\sim& |\Sigma_v| \cdot \frac{1}{(2L)^d} \cdot \prod_{i=0}^{d-1} \chi^2 (2L-2i) \label{eqn:determinant_distribution} \\
  \ln|C_v| &\sim& \ln|\Sigma_v| - d \cdot \ln(2L) + \sum^{d-1}_{i=0} \Lambda(2L-2i)
\label{eqn:log_determinant_distribution}  
\end{eqnarray}

In a given homogeneous POLSAR area, the parameters $\Sigma_v$, $d$ and $L$ can be considered as constant.
Thus Eqn. \ref{eqn:determinant_distribution} gives the theoretical explaination that: 
  in the original POLSAR domain, a multiplicative speckle noise pattern is present.
At the same time, Eqn. \ref{eqn:log_determinant_distribution} shows that
  the logarithmic transformation converts this into a more familiar additive noise.  

Since chi-squared random variables $X\ \sim\ \chi^2(k)\ $ follows a known PDF:
\begin{equation}
pdf(x;2L) =
  \frac{x^{L-1} e^{-x/2}}{2^L \Gamma\left(L\right)}
\label{eqn:chi_squared_dist_pdf:chap4}
\end{equation}
Applying the variable change theorem, 
  its log-transformed variable follows the PDF of:
\begin{equation}
  pdf(x;2L=k) = \frac{e^{Lx-e^x/2}}{2^{L}\Gamma(L)}
\end{equation}

As the PDFs become available, the characteristic functions (CF) of both the chi-squared and log-chi-squared random variables
  can be written as:
  \begin{eqnarray}
    CF_\chi(t) &=& (1-2it)^{−L} \\ 
    CF_\Lambda(t) &=& 2^{it} \frac{\Gamma(L+it)}{\Gamma(L)} \label{eqn:log_chi_squared_characteristic_function}
  \end{eqnarray}
Subsequently their means and variances can be computed from the given characteristic functions.
They are:
  \begin{eqnarray}
    avg \left[ \chi(2L) \right]&=&2L \\
var \left[ \chi(2L) \right]&=&4L \\
avg \left[ \Lambda(2L) \right] &=& \psi^0(L) + \ln2 \\
var \left[ \Lambda(2L) \right] &=& \psi^1(L)
  \end{eqnarray}
  where $\psi^0()$ and $\psi^1()$ stands for digamma and trigamma function respectively.

Since the average and variance of both chi-squared distribution and log-chi-squared distribution are constant,
  the product and summation of these random variables also has fixed summary statistics.
Specifically:
\begin{align*}
  avg \left[ \prod^{d-1}_{i=0} \chi^2(2L-2i) \right] &= 2^d \cdot \prod^{d-1}_{i=0} (L-i), \\
  var \left[ \prod^{d-1}_{i=0} \chi^2(2L-2i) \right] &= \prod^{d-1}_{i=0} 4(L-i)(L-i+1) - \prod^{d-1}_{i=0} 4(L-i)^2, \\
  avg \left[ \sum^{d-1}_{i=0} \Lambda(2L-2i) \right] &= d \cdot \ln{2} + \sum^{d-1}_{i=0} \psi^0(L-i), \\
  var \left[ \sum^{d-1}_{i=0} \Lambda(2L-2i) \right] &= \sum^{d-1}_{i=0} \psi^1(L-i)
\end{align*}

Combining these results with Eqns. \ref{eqn:determinant_distribution} and \ref{eqn:log_determinant_distribution}, we have:
%\begin{eqnarray}
%\end{eqnarray}
\begin{align}
  avg \left[ |C_v| \right]  &= \frac{|\Sigma_v|}{L^d} \prod^{d-1}_{i=0} (L-i)\\
  var \left[ |C_v| \right]  &=   \frac{|\Sigma_v|^2 \left[ \prod^{d-1}_{i=0} (L-i)(L-i+1) - \prod^{d-1}_{i=0} (L-i)^2 \right] }{L^{2d}} \label{eqn:var_det_is_heteroskedastic}\\
  avg \left[ \ln |C_v| \right] &= \ln |\Sigma_v| - d \cdot \ln{L}  + \sum^{d-1}_{i=0} \psi^0(L-i) \label{eqn:avg_log_det} \\
  var \left[ \ln |C_v| \right] &=  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:var_log_det_is_homoskedastic}
\end{align}

Over a real and captured image, while the paramaters $d$ and $L$ do not change for the whole image,
  the underlying $\Sigma_v$ is expected to differ from one region to the next.
Thus over an heterogeneous scene, the stochastic process for $|C_v|$ and $\ln |C_v|$ varies depending on the underlying signal $\Sigma_v$. 
In such context, Eqn. \ref{eqn:var_det_is_heteroskedastic} implies that the variance of $|C_v|$ also differs depending on the underlying signal $\Sigma_v$, which indicates its heteroskedastic property.
At the same time, in the log-transformed domain, Eqn. \ref{eqn:var_log_det_is_homoskedastic} shows that
  the variance of $\ln |C_v|$ is invariant and independent of $\Sigma_v$ manifesting its homoskedastic nature.

\section{Consistent Measures of Distance for POLSAR}
\label{sec:distance_measure}

Similar to the way dispersion and contrast is defined in our previous work \cite{Le_2013_TGRS_SAR_MSE},
  this section introduces the consistent sense of distance in a few different perspective.
First assumming that the true value of the underlying signal $\Sigma_v$ is known \textit{a priori},
the following random variables,
  namely ratio ($\mathbb{R}$) and log-distance ($\mathbb{L}$),
  are observable according to their definitions:
%Eqns. \ref{eqn:prod_chi_squared_rv} and \ref{eqn:sum_log_chi_squared_rv} lead straight to the definition of the following random variables, which is the :

\begin{eqnarray}
  \mathbb{R} &=& \frac{|C_v|}{|\Sigma_v|} \label{eqn:determinant_ratio_observables}\\
  \mathbb{L} &=& \ln|C_v| - \ln|\Sigma_v| \label{eqn:log_distance_observables} 
\end{eqnarray}
From another perspective where the POLSAR is known coming from an homogeneous area but the true value of the underlying signal $\Sigma_v$ is \textit{unknown}, consider the dispersion ($\mathbb{D}$) and contrast ($\mathbb{C}$) random variables being defined as:
\begin{eqnarray}
  \mathbb{D} &=& \ln{|C_v|} - avg(\ln{|C_v|}) \label{eqn:dispersion_observable}\\
  \mathbb{C} &=& \ln(|C_{v1}|) - \ln(|C_{v2}|) \label{eqn:contrast_observable}
\end{eqnarray}

Taking the results from Eqns. \ref{eqn:determinant_distribution}, \ref{eqn:log_determinant_distribution} and \ref{eqn:avg_log_det} we have
\begin{eqnarray}
\mathbb{R} &\sim& \frac{1}{(2L)^d} \cdot \prod_{i=0}^{d-1} \chi^2 (2L-2i) \label{eqn:determinant_ratio_distribution} \\
\mathbb{L} &\sim&  \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln(2L)
\label{eqn:log_determinant_distance_distribution} \\ 
 \mathbb{D} &\sim& \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2} + k
\label{eqn:dispersion_distribution} \\ 
 \mathbb{C} &\sim& \sum^{d-1}_{i=0} \Delta(2L-2i)
\label{eqn:contrast_distribution}  
\end{eqnarray}
with $\Delta(2L) \sim \Lambda(2L) - \Lambda(2L)$
and $k=\sum^{d-1}_{i=0} \psi^0(L-i)$

Also given the characteristic functions (CF) for the elementary components $\Lambda(2L)$ written in Eqn. \ref{eqn:log_chi_squared_characteristic_function}, 
  Appendix \ref{sec:appendix_b} derives the characteristic functions for the summative random variables as:
\begin{align}
  CF_{\Lambda^d_L}(t) &= \frac{2^{idt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\mathbb{L}}(t) &= \frac{1}{L^{idt} \Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\mathbb{D}}(t) &= \frac{e^{ikt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\Delta(2L)} &= \frac{\Gamma(2L) B(L-it,L+it)}{\Gamma(L)^2} \\
  CF_{\mathbb{C}}(t) &=  \prod^{d-1}_{j=0} \frac{\Gamma(2L-2j) B(L-j-it,L-j+it)}{\Gamma(L-j)^2}
\end{align}

Since each elementary simulation component follows fixed distributions (i.e. $\chi^2(2L), \Lambda(2L), ... $),
  it is natural that these variables also follow fixed distributions.
Moreover, they are independent to $\Sigma_v$.
This serves as conclusive evidence that
  these random variables follows consistent and fixed distributions,
  regardless of the underlying signal $\Sigma_v$.

\section{Validating the models against real-life data}
\label{sec:polsar_models_validation}

This section describes an experiment to validate the models above against real-life captured data.
The validation procedure is quite straightforward.
Given that the stochastic models have been derived in the previous sections, 
  they can be graphically visualized by the histogram plots of the simulated data.
At the same time, the form of the real-life practical data is also observable via histogram plots of the data samples extracted from an homogeneous area.
Therefore, the theoretical models can be validated 
  if for the same parameters 
  the two plots match each other reasonably well.

As a demonstration, a homogeneous area was chosen from the AIRSAR Flevoland POLSAR data as experimental data samples.
Then theoretical models are employed in an attempt to explain the data.
The validating models include:
  the determinant and its log-transformed models, together with the dissimilarity measures namely: the determinant ratio, the log-distance, the dispersion and the contrast measures of distance.
  
The models are closely related.
Given the same parameter set, the determinant and determinant ratio are just scaled version of each other.
Meanwhile, the log-determinant, the log-distance and the dispersion are also just shifted version of each other.
Thus ideally speaking
  if one model is validated all the other models will also be,
  assuming that all the parameters of the image are known exactly.
Still in this section, all the models will be made subject to investigation.

Among all these models, the least-assumed stochastic process for dispersion and contrast measures of distance are validated first.
For each pixel in the region, the determinant of the covariance matrix is computed and the log-transformation is applied.
Then the average of POLSAR covariance matrix’s determinant in the log-transformed domain, i.e. $avg(ln|C_v|)$, is measured for dispersion.
Subsequently the observable samples of dispersion and contrast are computed according to Eqns. \ref{eqn:dispersion_observable} and \ref{eqn:contrast_observable}.
Then their histograms are traced out.

At the same time, theoretical simulations according to Eqns. \ref{eqn:dispersion_distribution} and \ref{eqn:contrast_distribution} are carried out.
The nominal value of 4 was taken as the dataset's number of look,
 while the dimensional number is set to 3 or 2 respectively depending on whether full or partial polarimetric SAR dataset is being investigated.
All the histogram plots are presented in Fig. \ref {fig:verify_polsar_2x2_simulation_dispersion_contrast}.
Apparently, a visual match is observable which verify the applicability of the theoretical models for the dispersion and contrast measures of distance.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[part-pol (2x2) dispersion]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_dispersion_distribution.eps} 
		 \label{dispersion_2x2}
	} 
	\hfill	
	\subfloat[part-pol (2x2) contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_contrast_distribution.eps} 	
		 \label{contrast_2x2}
	} \\
	\subfloat[full-pol (3x3) dispersion]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_dispersion_distribution.eps} 
		 \label{dispersion_3x3}
	} 
	\hfill	
	\subfloat[full-pol (3x3) contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_contrast_distribution.eps} 	
		 \label{contrast_3x3}
	}
\end{tabular}
\caption{Validating the dispersion and contrast models against both partial and full polarimetric AIRSAR Flevoland data.}
\label{fig:verify_polsar_2x2_simulation_dispersion_contrast}
\end{figure}

Apart from dispersion and contrast,
the other four models to be investigated require an estimation of the ``true'' underlying signal $|\Sigma_v|$. 
There are two ways to estimate this quantity over an homogeneous area.
The traditional way is to simply set the true signal equal to the average of the polsar covariance matrix in its original domain, i.e. $\Sigma_v = avg(C_v$).
Another approach is to estimate the true signal from the average of the log-determinant of the polsar covariance matrix (i.e. $avg[ln|C_v|]$) using Eqn. \ref{eqn:avg_log_det}.
Both approaches will be explored in this section.
However, given that the log-determinant average has already been computed earlier, 
  the second approach is used first for the validation of determinant-ratio and log-distance.

Fig. \ref{fig:verify_polsar_2x2_simulation_det_ratio_log_distance} validate the models of determinant-ratio and log-distance against real-life data.
In this experiment, the theoretical models is simulated from Eqns \ref{eqn:determinant_ratio_distribution} and \ref{eqn:log_determinant_distance_distribution},
  while the observable samples are computed using Eqns \ref{eqn:determinant_ratio_observables} and \ref{eqn:log_distance_observables}
  with the true signal estimated from the log-determinant average, i.e. $avg(\ln|C_v|)$.
Again a reasonable match is observed which validates the models for log-distance and determinant ratio.  
 
\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[part-pol (2x2) determinant ratio]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_determinant_ratio_distribution.eps} 
		 \label{determinant_ratio_2x2}
	} 
	\hfill	
	\subfloat[part-pol (2x2) log distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_log_distance_distribution.eps} 	
		 \label{log_distance_2x2}
	} \\
	\subfloat[full-pol 3x3 determinant ratio]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_determinant_ratio_distribution.eps} 
		 \label{determinant_ratio_3x3}
	} 
	\hfill	
	\subfloat[full-pol 3x3 log distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_log_distance_distribution.eps} 	
		 \label{log_distance_3x3}
	}
\end{tabular}
\caption{Validating determinant-ratio and log-distance models with $|\Sigma_v|$ is computed using $avg(\ln|C_v|)$}
\label{fig:verify_polsar_2x2_simulation_det_ratio_log_distance}
\end{figure}

Since the models for the determinant and log-determinant are just scaled or shifted version of the models for determinant-ratio and log-distance, similar validation results are to be expected. 
And if the  true signal are computed in the same manner as described before then in fact similar match can be easily observed. 

However, a more interesting  phenomena is to be described.
It happens in the validation process for determinant and its log-transformed model,
  where the theoretical response is taken from the simulated stochastic process described by Eqns. \ref{eqn:determinant_distribution} and \ref{eqn:log_determinant_distribution}.
%For such simulation, an estimation of  the true signal is needed.
The interesting phenomena happens when the true signal is estimated by the first approach i.e. equal to the average of the sample covariance matrix in its original domain.
Interestingly, this approach results in a different estimation for the true signal with reference to the method described earlier.

Subsequently the validation plots, which are presented in Fig \ref{fig:verify_polsar_2x2_simulation_det}, exhibit some small discrepancies.
The differences are easier to observe in the log-determinant plots, 
  where except for some small shifted effects, the shapes of the models and the practical data exhibits certain resemblance.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[verify polsar 2x2: determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_determinant_distribution.eps} 
		 \label{determinant_2x2}
	} 
	\hfill	
	\subfloat[verify polsar 2x2: log-determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_log_det_distribution.eps} 	
		 \label{log_det_2x2}
	} \\ 
	\subfloat[verify polsar 3x3: determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_determinant_distribution.eps} 
		 \label{determinant_3x3}
	} 
	\hfill	
	\subfloat[verify polsar 3x3: log-determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_log_det_distribution.eps} 	
		 \label{log_det_3x3}
	} 
\end{tabular}
\caption{Validating determinant and log-determinant models with $\Sigma_v = avg(C_v)$}
\label{fig:verify_polsar_2x2_simulation_det}
\end{figure}

In short the least-assumed dispersion and contrast measures of distance are shown to match reasonably well with the practical data.
The same can be stated for the other four models, namely: determinant, log-determinant, determinant ratio and log-distance,
  if the underlying parameters can be estimated reasonably well for the given image.   
However as described above a single ``true signal'' $|\Sigma_v|$ can have two different estimated values,
  depending on which estimation method was being used.
The discrepancy suggests that at least one parameter for the models was wrongly employed.

But what model parameter were used wrongly, and even if that can be corrected, would a better match become observable?
The question is answered in Section \ref{sec:improve_the_match_bw_theory_practice}, 
  where not only the look number is shown to be misused
  but also the match of between the theoretical model and the practical data is shown to improve as well once a better look number (ENL) is estimated.
For now, let us contend that:
  using appropriate estimation of the parameters, 
  the proposed models match reasonably well with the practical data.

\section{SAR as the Special Case of Polarimetric SAR}
\label{sec:sar_special_case_of_polsar}

The prevous section has validated the use of our models for 3-dimensional $d=3$ full polarimetric and two dimensional $d=2$ partial polarimetry cases.
In this section, the focus is on the case where the dimensional number is reduced to 1 $d=1$.
Physically this means the multi-dimensional POLSAR dataset is collapsed into the one-dimensional and classical SAR data.
Mathmatically, the sample covariance matrix is reduced to the sample variance
  and the determinant equates the scalar value.
On another hand, it is well known that for SAR data, variance equals intensity.
Thus the special case of our result is investigated carefully and is shown to be consistent with previous results for SAR intensity data.
This can be thought of 
  either as a cross-validation evidence for the proposed POLSAR models
  or alternatively as having SAR as the special case of POLSAR. 
%  with well known results for SAR intensity is presented.

The results so far for our models can be summarized as:
\begin{align}
  \mathbb{R} &= \frac{|C_v|}{|\Sigma_v|} \sim \frac{1}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i) \\% \label{eqn:polsar_ratio_det_cov_dist} \\
  \mathbb{L} &= \ln{|C_v|} - \ln{|\Sigma_v|} \sim \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \\ %\label{eqn:polsar_dispersion_log_det_cov_dist} \\
  \mathbb{D} &= \ln{|C_v|} - avg(\ln{|C_v|}) \sim \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \ln{2} + k\\
  \mathbb{C} &= \ln{|C_{1v}|} - \ln{|C_{2v}|} \sim \sum^{d-1}_{i=0} \Delta(2L-2i) \\
  \mathbb{A} &= avg(\mathbb{L}) = \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \\ %\label{eqn:polsar_dispersion_averages} \\
  \mathbb{V} &= var(\mathbb{L}) = \sum^{d-1}_{i=0} \psi^1(L-i) \\ %\label{eqn:polsar_dispersion_variance} \\
  \mathbb{E} &= mse(\mathbb{L}) =\left[ \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \right]^2 +  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_mse} 
\end{align}

Upon setting $d=1$ into the above models,
  Appendix \ref{sec:appendix_sar_special_case_of_polsar} shows that the reduced results are consistent with
not only the following results from the our previous works on single-look SAR \cite{Le_2013_TGRS_SAR_MSE}, i.e. $d=L=1$,
\begin{align*}
  I &\sim \bar{I} \cdot pdf \left[ e^{-R} \right] \\
  \log_2{I} &\sim \log_2{\bar{I}} + pdf \left[ 2^xe^{-2^x}\ln2 \right] \\
  \mathbb{R} &= \frac{I}{\bar{I}} \sim pdf \left[ e^{-x} \right]  \\
  \mathbb{L} &= \log_2{I} - \log_2{\bar{I}} \sim pdf \left[ 2^xe^{-2^x}\ln2 \right]\\
  \mathbb{D} &= \log_2{I} - avg(\log_2{I}) \sim pdf \left[ e^{-(2^xe^{-\gamma})} 2^xe^{-\gamma} \ln2 \right] \\
  \mathbb{C} &= \log_2{I_1} - \log_2{I_2} \sim pdf \left[ \frac{2^x}{(1+2^x)^2} \ln2 \right] \\
  \mathbb{A} &= avg(\mathbb{L}) = -\gamma / \ln{2} \\
  \mathbb{V} &= var(\mathbb{L}) = \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  \mathbb{E} &= mse(\mathbb{L}) = \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{align*}
but also the following well-known results for multi-look SAR, i.e. $d=1,L>1$:
  \begin{eqnarray}
I &\sim& pdf \left[ \frac{L^L x^{L-1} e^{-Lx/\bar{I}}}{\Gamma(L) \bar{I}^L} \right] \\
N = \ln{I} &\sim& pdf \left[ \frac{L^L}{\Gamma(L)} e^{L(x-\bar{N})-Le^{x-\bar{N}}} \right]
  \end{eqnarray}
Furthermore, the following results for multi-look SAR data,
  which can be thought of 
    either as extensions of the corresponding single-look SAR results
    or as simple cases of the POLSAR results
  are also derived as:
  \begin{align*}
    \mathbb{R} &= \frac{I}{\bar{I}} \sim pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \label{eqn:multi_look_SAR_ratio_dist} \right]\\
    \mathbb{L} &= \ln{I} - \ln{\bar{I}} \sim pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right] \\
    \mathbb{D} &= \ln{I} - avg(\ln{I}) \sim pdf \left[ \frac{e^{L[x-\psi^0(L)]-e^{[x-\psi^0(L)]}}}{\Gamma(L)} \right] \\
    \mathbb{C} &= \ln{I_1} - \ln{I_2} \sim pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \right] \\
    \mathbb{A} &= avg(\mathbb{L}) = \psi^0(L) - \ln{L} \\
    \mathbb{V} &= var(\mathbb{L}) = \psi^1(L) \\
    \mathbb{E} &= mse(\mathbb{L}) = \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
  \end{align*}

This newly derived models for multi-look SAR data can also be validated against real-life data.
Fig. \ref{fig:verify_multi_look_SAR_dispersion_contrast_models} presents the the results of an experiment carried out for the stated purpose.
In the experiment the intensity of a single-channel SAR data (HH) for a homogeneous area in the AIRSAR Flevoland dataset is extracted.
Then the histograms for the log-distance and and contrast is plotted against the theoretical PDF given above.
The ENL is set to the nominal number of 4.
And good visual match is apparent in the final results.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[verify multi-look SAR log-distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_multi_look_sar_dispersion_pdf.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[verify multi-look SAR contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_multi_look_sar_contrast_pdf.eps} 	
		 \label{multi_look_contrast}
	}
\end{tabular}
\caption{Multi-Look SAR dispersion and contrast: modelled response matches very well with real-life captured data.}
\label{fig:verify_multi_look_SAR_dispersion_contrast_models}
\end{figure}
      
\section{Handling certain discrepancy between the theoretical model and pratical data}
\label{sec:improve_the_match_bw_theory_practice}

Even though the initial assumptions for the proposed theory is intentionally kept to minimal, 
  like all other similar models, the proposed model in this paper is built upon certain presumptions.
Practical conditions however may not always satisfy these prerequisites.
In this section, certain gaps between the conditions found in practical real-life data and the theoretical assumptions are discussed.
And it is shown that: the theoretical model proposed can handle the practical data, even when these ``imperfections''  are taken into account.

There are two main ``imperfections'' that are usually found in practical POLSAR data with reference to the theoretical model.
The first is the mutually independent assumption for each component in the POLSAR target vector $s$.
Practically however high correlation is routinely observable between the POLSAR data components,
  specifically between $S_{hh}$ and $S_{vv}$.
This phenomena also presents in our AIRSAR dataset, where $\Sigma_v = avg(C_v) = \begin{vmatrix} 0.0084 & 1 \cdot 10^{-6} + 4 \cdot 10^{-4} i & 0.0071 - 0.0017 i \\ 1 \cdot 10^{-6} - 4 \cdot 10^{-4} i & 0.0017 & -3 \cdot 10^{-4} - 2 \cdot 10^{-4} i \\ 0.0071 + 0.0017 i & -3 \cdot 10^{-4} + 2 \cdot 10^{-4} i & 0.0122 \end{vmatrix}$.
Despite the mismatch,
  astute reader would probably notice that the proposed model apparently still valid under such condition as evidenced by the part-pol (HH-VV) and full-pol plots in Figs. \ref{fig:verify_polsar_2x2_simulation_dispersion_contrast} to \ref{fig:verify_polsar_2x2_simulation_det}.
This suggests that the proposed model is also applicable on correlated POLSAR components,
  eventhough a full explaination for this, however, is outside the scope of this paper.

Another assumption of the model (for both SAR and POLSAR) is that the samples are statistically independent to each other.
This is a reasonable assumption given that 
  the transmission and receipt of analog signals are done independently for each radar pulse, i.e. for each resolution cell.
Thus theoretically speaking, adjacent pixels in an image can be assumed to be statistically independent.

However, the actual imaging mechanism of a real-life (POL)SAR processor is that of digital nature,
where the analog signal is to be converted into a digital data-set. 
Specifically, the analog signal in SAR 
  which is characterized by the pulse bandwidth measurement,
  is fed into an analog-to-digital sampling and conversion process 
  which is characterized by its sampling rate.
Theoretically it is possible to define a sampling rate to ensure that each digital pixel correspond exactly to an analog physical cell resolution.
Practically however, to ensure ``perfect reconstruction'' of the analog signal, the sampling rate is normally set at a slightly higher value than the theoretical mark.
This results in a higher number of samples / pixels than the number of physical cells available in the scene.  

Stated differently, in practical data each physical radar cell is spread to more than one pixel
  and each pixel now contains less than one physical analog cell.
This high sampling rate also results in 
  a significantly higher correlation between pairs of pixels that maybe related within a single physical cell resolution 
  than the correlation found between pairs of pixels that are further away and hence having less physical relation to each other.
It also results in reduced effective number of look, 
  in which say a window of 3x3 pixel actually contains less than 9 physical analog cells. 
The former phenomena is partially explained in \cite{Raney_1988_TGRS_666} for SAR,
  while the later is experimental observed for POLSAR data in \cite{Lee_1994_TGRS_1017} and \cite{Anfinsen_2009_TGRS_3795}.
The oversampling practice is also documented by the producers of SAR processors.
For AIRSAR, the sampling rate and pulse bandwidth combinations are either 90/40MHz or 45/20MHz \cite{JPL_2013_Web_AIRSAR_Impl}.
While for RadarSat2, the pixel resolution and range - azimuth resolutions for SLC fine-quad mode is advertised as $(4.7 \cdot 5.1)m^2/(5.2 \cdot 7.7)m^2$ \cite{MDA_2013_Web_RadatSat2_Description}

The proposed model can handle this imperfection that is available in pratical data.
The trick is that instead of using the nominal Number of Look given by the SAR processor,
  an ENL estimation procedure is employed. %the model validation can make use of the Effective Number of Looks that is manually estimated from a given practical dataset.
The first part of this section details a simple ENL estimation technique for POLSAR data.
While the second part demonstrates how the practical imperfection manifest itself and how it can be handled in a RADARSAT2 dataset.
It also illustrates how the match shown in Section \ref{sec:polsar_models_validation} for the AIRSAR Flevoland dataset can be improved,
  by using ENL estimation.

\subsection{ENL Estimation}

This sub-section describes a few technique to estimate the Effective Number of Look (ENL) for a given POLSAR dataset.
The common approach in tackling this problem is by investigating the summary statistics of an known homogeneous area in the given data
  before making inferences about the inherent ENL.
The summary statistics for $|C_v|$ and $\ln|C_v|$ has been derived in Section \ref{sec:polsar_heterosked_model_and_log_transform}.
In fact Eqn. \ref{eqn:avg_log_det} indicates that there is a relationship among $|avg(C_v)|,avg(\ln|C_v|),d,L$.
Recall that in carrying out validation process for AIRSAR Flevoland data using the nominal look number of 4, this relationship was broken.
The reason for such broken relationship is believed to be an inexact look number was taken.
In a given POLSAR datasat, since all values of $|avg(C_v)|,avg(\ln|C_v|),d$ is known,
  it is possible to estimate the ``effective'' number of look, by finding $L$ that ensure the above relationship is valid.

In fact, this approach was taken in \cite{Anfinsen_2009_TGRS_3795},
  where an equation of exactly the same form as Eqn.  \ref{eqn:avg_log_det} was used to estimate the ENL.
Unfortunately, the only known way to solve the equation for the unknown $L$ requires the use of an ``iterative numerical method''.
Instead of relying on the equations for statistical mean to find ENL,
  our approach make used variance statistics in the homoskedastic log-domain to find ENL.
Since the determinant of POLSAR covariance matrix can be considered as the equivalence of the intensity in SAR data,
  this approach can be considered as the generic extension of our previous work on SAR ENL estimation \cite{Le_2013_TGRS_SAR_MSE} towards POLSAR data.
Specifically, Eqn. \ref{eqn:var_log_det_is_homoskedastic} can be rewritten as: 
\begin{equation}
  var \left[ ln|C_v| \right] = f(L) = \sum^{d-1}_{i=0} \psi^1(L-i)
  \label{eqn:expected_sample_var_log_as_function_of_enl}
\end{equation}
where $\psi^1()$ denotes tri-gamma function.

Thus theoretically, given some measurable value for $var  \left[ ln|C_v| \right]$, one could solve the above equation for the unknown $L$.
Interestingly that would also require some iterative computations.
Practically however, the shape of the right-hand-side can be pre-computed
  and for each computed value of $var  \left[ ln|C_v| \right]$, a corresponding value for $L$ can be found by referencing the variance value on the pre-computed graph.
And if a graph is too tedious to be carried around an approximation can be made using a back-of-the-envolope calculation given as:
  \begin{equation}
    \hat{L} = d \left( \frac{1}{var(\ln{|C_v|})} + 0.5 \right)
    \label{eqn:enl_estimation_formula}
  \end{equation}
Fig. \ref{fig:plot_enl_var_relation_1x1_and_2x2}
  not only shows the shapes of the function defined in Eqn. \ref{eqn:expected_sample_var_log_as_function_of_enl} for SAR and partial-POLSAR data $f_{d=1}(L)$ and $f_{d=2}(L)$
  but also illustrates the approximation power of the simplified formula (Eqn. \ref{eqn:enl_estimation_formula}).
  
\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[ENL and variance log-intensity relations for SAR data]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/plot_enl_var_relation_1x1.eps} 
		 \label{plot_enl_var_relation_1x1}
	} 
	\hfill	
	\subfloat[ENL and var(log-det) relations for partial POLSAR data]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/plot_enl_var_relation_2x2.eps} 	
		 \label{plot_enl_var_relation_2x2}
	} 
\end{tabular}
\caption{The relations between ENL and sample variance of log-determinant/log-intensity}
\label{fig:plot_enl_var_relation_1x1_and_2x2}
\end{figure}

\subsection{Using estimated ENL to better explain pratical data}
  
For this experiment an example RADARSAT2 dataset was used.
The dataset is in its Fine-Quad mode Single-Look format,
  and nine-look processing is applied before the dispersion histogram in log-transformed domain is computed for an homogeneous area.
The histograms for both one-dimensional SAR and two-dimensional partial POLSAR data are plotted in Fig. \ref{{fig:handling_radarsat2_oversampling_practice}}
  against the theoretical model for the nominal ENL value of 9.
The match however is not very good.

A better match can be achieved by estimating the ENL from the observable variance of the log-determinant,
  and the theoretical model is simulated for the estimated ENL
Then the new sample histogram is plotted in the same figure,
  which indicated a much better consistency.
This procedure can always be carried out for any given dataset,
  as long as an area of homogeneous area can be extracted.
  
\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Handling over-sampling practice in Radarsat2 one-dimensional SAR data (HH)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_radarsat2_oversampling_practice.sar.eps} 	
		 \label{sar}
	} 
	\hfill	
	\subfloat[Handling over-sampling practice in Radarsat2 partial POLSAR data (HH-HV)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_radarsat2_oversampling_practice.part_pol.eps} 	
		 \label{part_pol}
	}   
\end{tabular}
\caption{9-look processed Radarsat2 data do not exactly exhibit 9-look data characteristics. Homoskedastic model in log-transformed domain can successfully estimate the effective ENL and then explain the data reasonably well.}
\label{fig:handling_radarsat2_oversampling_practice}
\end{figure}

Fig. \ref{fig:handling_airsar_oversampling_practice_full_pol} shows that the over-sampling issue is also present in AIRSAR Flevoland dataset,
  eventhough to a much lesser-extent. %with the nominal 4-look data actually have an effective number-of-look around 3.22 only.
The ``corrected'' effective number-of-look offer observably better match between the model and real-life data.
The mis-match problem appears to depend on how much over-sampling were used in the dataset
  as well as the dimension of the data.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Handling over-sampling practice in AIRSAR full-pol dataset (contrast better?)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_airsar_oversampling_practice_full_pol_determinant_ratio.eps} 	
		 \label{sar}
	} 
	\hfill	
	\subfloat[Handling over-sampling practice in AIRSAR full-pol dataset]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_airsar_oversampling_practice_full_pol_log_distance.eps} 	
		 \label{part_pol}
	}   
\end{tabular}
\caption{AIRSAR Flevoland also exhibits phenomena of over-sampling practice, through at a lesser extend than the RADARSAT 2 data.}
\label{fig:handling_airsar_oversampling_practice_full_pol}
\end{figure}

\section{Evaluating POLSAR Speckle Filters using the consistent measures of distance}
%\section{Visually Evaluating POLSAR Speckle Filters over Heterogeneous Areas}
\label{sec:evaluating_polsar_filters}

Previous sections have developed a model for polsar, which is also shown to be applicable to sar,
  in this section, the use of consistent measures of distance in the context of polsar speckle filtering is briefly explored.
It has been found \cite{Rignot_1993_TGRS_896} that for sar data set that in its original domain: 
   ratio is a better evaluation than standard substractive residual. 
However, ratio residual is argued as not being natural for digital display \cite{Medeiros_2003_IJRS}.
Our previous work in the context of sar speckle filtering found that
  in log-transformed domains, this ratio is transformed into a subtractive residual that is homoskedastic.
  
The variance of sample log-determinant is shown linked to the ENL index.
This form the basis for evaluating POLSAR speckle filters over homogeneous areas.
The procedure is simple.
To evaluate a given POLSAR speckle filter over homogeneous areas,
  the filter is applied over any known homogeneous areas and the sample variance of log-determinant is measured.
The Equivant Number of Look (ENL) is then estimated
  either by referencing the prepared graphs given by Eqn. \ref{eqn:expected_sample_var_log_as_function_of_enl} 
  or alternatively by setting the measured variance value into $var[\ln{|C_v|}]$ in Eqn. \ref{eqn:enl_estimation_formula}.

In order for such a procedure to be generic enough, it is important that the given POLSAR speckle filter preserve the consistency property in the log-transformed domain.
That can be tested by applying the POLSAR filter into different sets of homogeneous area and investigate the plots of the dis-similarity measures presented above.
Fig. \ref{fig:boxcar_3x3_preserves_consistency} presents two example plots to show that:
  the 3x3 POLSAR boxcar filter preserves the consistency property.
The boxcar filter is applied into 2 sets of part-pol AIRSAR data over Flevoland (HH-HV and VH-VV).
Log-determinant and the contrast measure is computed for the inputs and outputs filtered POLSAR data,
  and their plots are presented.
In fact, the test procedure can be applied on any of the models presented above.  

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Log-determinants histograms of boxcar 3x3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/boxcar_3x3_preserves_consistency.log_determinant.eps} 	
		 \label{log_determinant}
	} 
	\hfill	
	\subfloat[Contrast histograms of boxcar 3x3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/boxcar_3x3_preserves_consistency.contrast.eps} 	
		 \label{contrast}
	}   
\end{tabular}
\caption{POLSAR 3x3 boxcar filter preserves the consistency property. Consistency means: as long as the area is homogeneous, regardless of the underlysing signal $\Sigma_v$ the shapes of the histograms should be the same.}
\label{fig:boxcar_3x3_preserves_consistency}
\end{figure}

The consistency property of POLSAR speckle filter is important
  not only to make the estimation of ENL become general enough
  but also to ensure that any classification / detection algorithm
    which is based on the scalar and consistent measures of distance would work on both pre-filtered and post-filtered data.
Otherwise if a polsar speckle filter gives different plots for different homogeneous areas, then not only its enl estimation will be dependent on the underlying signal, 
But its output also shall not follow the statistical distribution family that characterize multi-look polsar.
Thus the preservation of this consistency is believed to be an important consideration for polsar speckle filter if he want a host of detection and classification algorithms to work on his filtered data output.

In evaluation over heterogeneous area, the consistent measures of distance may also be an invaluable tool.
 %in helping to evaluate POLSAR speckle filters.
For a start, since the model for log-determinant is additive and homoskedastic,
  log-determinant images may be better naturally suited for gray-level digital images.
specifically for evaluation of statistical estimators,
  It is both important and convinient to investigate the estimators' error / residual image. %plays an important role.

For future further analysis, the residual is defined here as the distance between the log-determinants of the filtered outputs and the original input. 
Ideally speaking, under the context of additive model,
  a perfect estimator's residual should be consists only of random noise.
And under the assumption of homoskedasticity, 
  the Gauss Markov theorem becomes applicable.
Thus the optimal estimator is expected to exhibits minimal Mean Squared Error.
In homogeneous scene, this is reflected in the expectation of minimal bias and variance (hence maximal ENL).
Over heterogeneous scene, where the underlying signal is not known apriori,
  the second best gauge is possibly to have the residual mse being as close as possible to the MSE of the inherent noise.
  
To illustrate the above analysis, an experiment is carried out to evaluate the performance of boxcar 3x3 and boxcar 5x5 POLSAR filter on the AIRSAR Flevoland partial polarimetric data (HH-HV).
A square 700x700 portion of the AIRSAR dataset is extracted, and the two POLSAR speckle filters is applied on to the patch.
Then the log-determinant images of the filtered outputs are display in Fig. \ref{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5}.
At the same time the residual is computed for both cases filters and the images are also displayed in the same figure.
Assumming the quantitative evaluation of SAR speckle filters can also be extended to POLSAR speckle filters,
  the Mean Squared Error (MSE) of the filters residuals are computed and compared with the ``optimal'' value.
This value is computed   
by setting $d=2,L=4$ into Eqn. \ref{eqn:polsar_dispersion_mse} making the expected MSE being $mse(\mathbb{L})=1.0132$.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Log-determinant Image of boxcar 3x3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_3.filtered.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[Log-determinant Image of boxcar 5x5 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_5.filtered.eps} 	
		 \label{multi_look_contrast}
	} \\
	\subfloat[Image of Log-determinant Residual for 3x3 filter (MSE=1.5594)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_3.residual.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[Image of Log-determinant Residual for 5x5 filter (MSE=2.1420)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_5.residual.eps} 	
		 \label{multi_look_contrast}
	} 
\end{tabular}
\caption{Visually Evaluating POLSAR Boxcar 3x3 vs. 5x5 Speckle Filters on AIRSA Flevoland part-pol data (HH-HV) with expected MSE=1.0312 at ENL=4. }
\label{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5}
\end{figure}
%Note if the picture does not look convincing enough
%another option here is to show 7x7 filter with more pronouced blurring MSE=2.5

Fig. \ref{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5} shows that not only the log-determinant image can offer a nice visualization of the scene, 
  but also the distortion impact of the filter can also be made visible by the residual image.
In visual evaluation, while it is quite hard to observe the worsening blurring-effects of the boxcar 5x5 speckle filter as compared to the 3x3 filter
in the additive log-determinant image of the filtered output 
  such a conclusion can be made relatively easier by visually investigating the residual image.

And when quantified evaluation is carried out
  where the residual mse is compared with the expected level of noise to be removed,
  the excessive blurring effects of the 5x5 filter become crystally clear.
In fact, even the 3x3 boxcar filter itself might be also a bit blurry.%,  as suggested by its relatively high residual values.
A conclusion which is hard to make just by looking at the filtered imagery.
However, by investigating the residual between the unfiltered input and the filtered results in the additive and homoskedastic model, both visual and quantitative evaluations offer conclusive evidence.

Much more detailed discussion on this topic, 
  under the context of evaluating sar speckle filter is published in our previous work \cite{Le_2013_TGRS_SAR_MSE}.
Unfortunately, due to space restriction, only a brief and critical exploration is explored here for polsar speckle filters.
This section serves more as an illustration of how the proposed theoretical model can be applied on practical scenario,
  as it is not as a full proposal for such an evaluation procedure for polsar speckle filters.

\section{Discussion and Conclusion}
\label{sec:discussion_conclusion}

\subsection{Related Work in Literature}
This sub-section reviews some relevant and published works on proposing different measures of distance for POLSAR data. 
specifically a few different matrix distances have been proposed and evaluated in recent review papers\cite{Dabboor_2013_IJRS_1492}\cite{Kersten_2005_TGRS_519}

The common used measure of distance for matrices are either the Euclidean or the manhattan distance.
They are defined in the following equations, respectively 
The Manhattan distance is
\begin{align}
  d(C_x,C_y) &= \sum_{i,j} |\mathbb{R} (C_x - C_y)_{i,j}| + \sum_{i,j} |\mathbb{I} (C_x - C_y)_{i,j}| \\
  d(C_x,C_y) &= \sqrt{\sum_{i,j} |C_x - C_y|_{i,j}^2 }
\end{align}
where $A_{i,j}$ denotes the (i,j) elements of the matrix A,
 $||$ denotes absolute values
and $\mathbb{R},\mathbb{I}$ denote the real and imaginary parts respectively.
In the context of polsar covariance matrix, however, they are not widely used 
  probably because of the multiplicative nature of the data.

In the field of POLSAR, the Wishart Distance is probably the most widely used as part of the well-known Wishart Classifier \cite{Lee_1999_TGRS}.
The distance is defined as \cite{Lee_1994_IJRS_2299}
\begin{equation}
  d(C_x,C_y) = \ln|C_y| + tr(C_xC_y^{-1})
\end{equation}
As a measure of distance, it main disadvantage is that $d(C_y,C_y) = \ln|C_y| \neq 0$.

Recent works have suggested a number of other dis-similarity measures.
They are: the asymmetric and the symmetric refined wishart distance\cite{Anfinsen_2007_ESA_POLINSAR},
\begin{align}
  d(C_x,C_y) &= \frac{1}{2} tr(C_x^{-1}C_y + C_y^{-1}C_x) - d \\
    d(C_x,C_y) &= \ln|C_x| - \ln|C_y| + tr(C_xC_y^{-1}) - d
\end{align}
the Bartlett distance\cite{Kersten_2005_TGRS_519},
  \begin{align}
  d(C_x,C_y) &= 2 \ln |C_{x+y}| - \ln |C_x| - \ln |C_y| - 2d\ln2
  \end{align}
the Bhattacharyya distance\cite{Lee_2011_IGARSS_3740},
\begin{equation}
  r(C_x,C_y) = \frac{|C_x|^{1/2} |C_y|^{1/2}}{|(C_x+C_y)/2|}
\end{equation}
and the Wishart Statistical test distance\cite{Cao_2007_TGRS_3454}
\begin{equation}
  d(C_x,C_y) = (L_x + L_y) \ln|C| - L_x \ln|C_x| - L_y\ln|C_y|
\end{equation}
.

In comparision to these formula, the distance measure for two covariance matrix proposed in this paper can be written as:
\begin{equation}
  d(C_x,C_y) =  \ln|C_x| - \ln|C_y| 
\end{equation}
At the first glance, while the propose formula may be a lot simpler, it is still very similar to others in making use of the log-determinant.

Closer investigation of these dissimilarity measures reveals that most of them are related to each other.
The Bhattacharyya distance is easily shown to be related to the Barlett distance.
At the same time the Barlett distance can be considered as the special case of the Wishart Statistical Test distance, where the two data set have the same number of look $L_x=L_y$.
And it is also intuitively trivial to arrive at the conclusion that the contrast measure of distance proposed in this paper have fixed statistical behaviour just by comparing the symmetric and asymmetric versions of the Refined Wishart distance, assuming that they are shown to follow fixed distributions.

The close relation among these is further supported by the fact that
In fact, in their proposal, all of the work referenced the statistical model developed in todocite as their foundation.
Interestingly, the change detection model also make use of determinant ratio and log determinant in its derivation.  
The next sub-section will illustrate how the log-determinant model studied in this paper can an alternative and simple derivation for the change-detection statistics.

%which intuitively should have its statistics bouded
%  as evidentally $tr(V_xV_y^{-1}) - p$ is bounded.

%The Wishart test statistics given by Cao where $V = \frac{\sum^{N_x+N_y}_{i=1}V_i}{N_x + N_y}$
%and $N_i$ is the number of pixel in cluster $V_i$. 

%Note that all Barlett distance, Anfinsen Revised Wishart distance and Cao Wishart test statistics are derived from Conradesen statistical model.
%\cite{Kersten_2005_TGRS_519} reviewed the distances
%  and stated $\ln{Q}$ is proportional to Bhattacharyya distance
%  which is defined for multi-variate Gaussian distribution $p_i=N(m_i,P_i)$ as
%  \begin{equation}
%    D_B={1\over 8}(m_1-m_2)^T P^{-1}(m_1-m_2)+{1\over 2}\ln \,\left({\det |P| \over \sqrt{\det |P_1| \, \det |P_2|} }\right)
%  \end{equation}
%where $m_i,P_i$ is the mean and covariances of the distributions
%and $P=(P_1+P_2)/2$.
%Lee KY gives \cite{Lee_2011_IGARSS_3740} Bhattacharyya distance for POLSAR as
%\begin{equation}
%  r(V_x,V_y) = \frac{|V_x|^{1/2} |V_y|^{1/2}}{|(V_x+V_y)/2|}
%\end{equation}.
%\cite{Lee_2011_IGARSS_3740}  also derive the revised Wishart distance from the log-likelyhood distance. 
%
%
%Wishart Chernoff distance given by Dabboor \cite{Dabboor_Thesis_2010}
%\begin{equation}
%  d(V_x,V_y) = \left[ \beta \ln|V_x| + (1-\beta) \ln|V_y| \right] - \ln | \beta V_x^{-1} + (1-\beta) V_y^{-1} |
%\end{equation}
%where $0<\beta<1$ is a parameter that minimizes $f(\beta)=e^{-d(V_x,V_y)}$ which ensure classification error is minimized.
%Minimal classification error is ensured by Chernoff bound
% which gives exponentially decreasing bounds on tail distributions of sums of independent random variables.
%For the complex Wishart distribution, the Chernoff bound is given by: $P(error) < p^\beta(C \in C_1) p^{1-\beta}(C \in C_2) e^{-f(\beta)}$
%Apparently, while the given methodology is a bit contrived,
%  it also used $\ln|C|$ as the base for comparision. 
%
%In conclusion, the Manhattan distance and Euclidian distance is probably suffers from heteroskedastic problem and hence is probably inconsistent.
%The other dis-similarity measures are
%  the Wishart test statistics\cite{Cao_2007_TGRS_3454}, %given by Cao [Cao et al., 2007]
%  the Barlett distance \cite{Kersten_2005_TGRS_519}, %reviewed by Kersten [Kersten et al., 2005]
%  and the revised Wishart distance \cite{Anfinsen_2007_ESA_POLINSAR}.% proposed by Anfinsen [Anfinsen et al., 2007].
%%Our friends in EADS, LKY and Timo [Lee and Bretschneider, 2011] shows derivations
%It has been shown that\cite{Lee_2011_IGARSS_3740} all these measures of distance are related.
%Specifically the Barlett distance is porportional to Bhattacharyya distance.
%At the same time the Revised Wishart distance also can be derived using the Conradsen statistics.
  
\subsection{The Likelyhood Statistics for POLSAR}

To detect if the two scaled multi-look POLSAR covariance matrix $Z_x$ and $Z_y$,
  which have $L_x$ and $L_y$ as the corresponding number of looks,
  come from the same underlying stochastic process,
the likelyhood ratio statistics for POLSAR covariance matrix is considered \cite{Conradsen_2003_TGRS_4} 
\begin{equation}
  Q = \frac{(L_x+L_y)^{d \cdot (L_x+L_y)}}{L_x^{d \cdot L_x} L_y^{d \cdot L_y}} \frac{|Z_x|^{L_x} |Z_y|^{L_y} }{|Z_x+Z_y|^{(L_x+L_y)}}
\end{equation}

Taking the log-transformation of the above statistics, and note that $C_{vx} = Z_x / L_x$, $C_{vy} = Z_y / L_y$ and $C_{vxy} = (Z_x + Z_y)/(L_x + L_y)$ it becomes 
\begin{eqnarray}
  Q &=& \frac{|C_{vx}|^{L_x} \cdot |C_{vy}|^{L_y} }{|C_{vxy}|^{L_x + L_y}} \nonumber \\
  \ln Q &=& L_x \ln |C_{vx}| + L_y \ln |C_{vy}| - (L_x + L_y) \ln |C_{vxy}| \nonumber
\end{eqnarray}

To detect changes, a test statistics is developed based on this measure of distance.
This means a distribution is to be derived for the dissimilarity measure.
However, originally in the proposed work, only an asymptotic distribution is derived.
In this sub-section, a statistical model is developed for this measure of distance.

Since both $Z_x$ and $Z_y$ follow complex wishart distribution with $L_x$ and $L_y$ degrees of freedom,
  $Z_x+Z_y$ also follows the complex wishart distribution with $L_x + L_y$ degrees of freedom.
In view of the models denoted in Eqn. \ref{eqn:log_determinant_distribution},
  it is evident that not only the bound for $\ln Q$, or equivalently $Q$, can be derived
  but the whole statistical distribution for it can be simulated as well:
\begin{eqnarray}
%  Q &\sim& \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y} \cdot (2(L_x+L_y))^{d (L_x + L_y)}}{(2 L_x)^{d \cdot L_x} \cdot (2 L_y)^{d \cdot L_y} (\chi^d_{L_x + L_y})^{L_x + L_y}} \\
%    &=& \frac{(L_x+L_y)^{d (L_x + L_y)}}{(L_x)^{d \cdot L_x} \cdot (L_y)^{d \cdot L_y} } \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y}}{(\chi^d_{L_x + L_y})^{L_x + L_y}} \\
  \ln{Q} &\sim&  k + L_x \Lambda^d_{L_x} + L_y \Lambda^d_{L_y} - (L_x + L_y) \Lambda^d_{(L_x + L_y)} \\
  Q &\sim& e^k \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y}}{(\chi^d_{L_x + L_y})^{L_x + L_y}}  
\end{eqnarray}
where $k = d \left[ (L_x + L_y) \ln(L_x + L_y) - L_x \ln{L_x} - L_y \ln{L_y} \right]$.

In the common case of $L_x = L_y$, the test statistics become
$\ln Q = \ln |C_{vx}| + \ln |C_{vy}| - 2 |\ln C_{vxy}|$.
This and the barlett distance introduced earlier are closely related, in fact they are just shifted versions of each other.
under exactly the same assumptions, 
The contrast model which is written as $\mathbb{C} = \ln C_{vx} - \ln C_{vy}$ and presented above should provides another consistent and equivalent approach,
  with probably simpler conceptual model and computational derivations. 
%a slightly simpler statistics.
The details application of this in edge-detection however is outside the scope of this paper.

\subsection{Discussion}

Let us start the discussion by noting a few theoretical properties of the proposed statistical model
First, The use of covariance matrix log-determinant may be related to the standard eigen-decomposition method of the second order statsitics POLSAR matrices.
In fact, the log-determinant can also be computed as the sum of log-eigen values.
Specifically $\ln{|M|} = \sum \ln{\lambda_M}$ where $\lambda_M$ denotes all the eigen-values of M.
Thus similar to other eigen-value based approach (e.g. Entropy/Anisotropy, ...),
  the models presented here is invariant to polarization basis transformations.

Second, the model is developed for the polsar covariance matrix.
However, since the polsar coherent matrix is related with the covariance matrix via an unitary transformation, which preserves the determinant as invariant,
The model should also be applicable on the coherency matrix.

The model is far from complete.
 It calls for the reduction of the multi-dimensional POLSAR data into a scalar value.
While this is probably desirable for a wide range of application where a one-dimensional number is required to represents the complex multi-dimensional data,
  such a reduction is probably not lossless.
Thus similar to the way the Wishart Classifier is employed, to better understand polsar data
  the use of this technique should be complemented with some high-dimensional POLSAR target-decomposition techniques (e.g. Freeman Durden or entropy/anisotropy TODO:CITE ...)

But at the same time, the model is also promising.
The models presented in this paper are first developed for partial and monostatic POLSAR data,
It is then shown to be also applicable to the traditional sar data.
Since the model's assumptions are quite minimal, It may also work on bi-static and intererometric data,
  though that requires further investigations.
Other interesting phenomena which may warrant more study include the applicability of the model on correlated polsar channels ($S_{hh},S_{vv}$) as well as a better explanation in the use of mse to evaluate polsar speckle filters.

Many practical applications may also be developed using the model and its derivatives.
First, The model allow for the estimation and simulation of non-natural equivalent number of look.
This come in especially handy when some real-life data is given,
  where the effective number of look may not be equals to the nominal stated number-of-look after multi-look-processing.
In such case, better-match models can be derived
  by roughly estimating the effective ENL 
  which usually results in a number with fractions.

Similar to the way other measures of distance can be used to derive POLSAR classifier \cite{Lee_1999_TGRS}, change detector \cite{Conradsen_2003_TGRS_4}, edge detector \cite{Schou_2003_TGRS_20} or other clustering cite and speckle filtering techniques \cite{Le_2010_ACRS} \cite{Le_2011_ACRS} 
new detection / classification, clustering or speckle filtering algorithms can be derived using the models presented in this paper.
And since extensive evidence have been shown supporting the use of MSE for SAR data,
  it is reasonable to expect the relevant of MSE for POLSAR data.
If that is the case, a large number of existing algorithms can become applicable to the POLSAR model in log-transformed domain,
  which has been shown to be both additive and homoskedastic.   

\subsection{Conclusion}
\label{sec:conclusion}

In conclusion, an additive and homoskedastic model, 
  which results in several scalar and consistent measures-of-distance for multi-variate POLSAR data
  were proposed in this paper.
The theoretical model is shown to be powerful.
Not only it can provide alternative and sometimes simpler explanations to a range of theoretical concepts:
  i.e. POLSAR test statistics or ENL estimation 
but it also puts several well-known models for the traditional SAR within its natural coverage. %as its natural special case.
The statistical model is based on the determinant of the POLSAR covariance matrix,
  which when converted into one-dimensional data
  is gracefully transformed into the traditional SAR intensity.
Consequently, the derived dis-similarity measures may be employed in a wide range of application
  where a scalar number is required to represent the complex multi-dimensional POLSAR data.
The model is also shown to be practically versatile. 
It is capable of handling a few imperfect conditions found in practical data.   
As both an application of the model,
  as well as an extension of our previous work in evaluating SAR speckle filters\cite{Le_2010_ACRS},
  the application of these additive and homoskedastic distances in the context of evaluating POLSAR speckle filters is briefly explored.
And intially promising results are reported.  
  
%Just like it is shown for the simpler case of SAR data processing\cite{Le_2010_ACRS},
%  when these distances are computed in the log-transformed domain,
%  their theoretical statistic models become additive and homoskedastic.
%The models are shown to be theoretically powerful.
%Not only they can provide alternative and sometimes simpler explainations to a range of theoretical concepts:
%  i.e. change detection test statistics or ENL estimation
%but also a number of results for one-dimensional SAR can be shown as special cases of the POLSAR models.
%They are also pratically versatile enough
%  capable of explaining the imperfect over-sampling practice evident in RADARSAT2 data.
%Finally, to extend our previous work in evaluating SAR speckle filters,
%  the applicaton of these additive and homoskedastic distances in the context of evaluating POLSAR speckle filters is briefly explored
%  with promising results reported.
 

\appendices
\section{Homoskedastic Model for the Log-Determinant}
\label{chap:appendix_a}

\subsection{Log-Chi-Square Distribution and its Derivatives}
%\section{Log-Chi-Square Distribution}
\renewcommand{\theequation}{\thesection.\arabic{equation}}
\setcounter{equation}{0}

This section provides the mathematical derivations for the log-transformed version of chi-squared random variables.

Chi-squared random variables $\chi\ \sim\ \chi^2(k)\ $ follows the pdf:
\begin{equation}
pdf(\chi;\,k) =
  \frac{\chi^{(k/2)-1} e^{-\chi/2}}{2^{k/2} \Gamma\left(\frac{k}{2}\right)}  
\label{eqn:chi_squared_dist_pdf:appdixA}
\end{equation}

Setting L=k/2 into Eqn. \ref{eqn:chi_squared_dist_pdf:appdixA}
\begin{equation}
pdf(\chi) = \frac{\chi^{L-1}e^{-\chi/2}}{2^L\Gamma(L)}
\end{equation}

Applying the variable change theorem, which states that: if $y=\phi(x)$ with $\phi(c)=a$ and $\phi(d)=b$, then:
\begin{equation}
 \int_a^b \! f(y) \, dy = \int_c^d \! f[\phi(x)] \frac{d\phi}{dx} dx
\end{equation}
into the log-transformation, which changes the random variables $\Lambda=ln(\chi)$, we have:
\begin{eqnarray*}
  d\chi &=& e^\Lambda d\Lambda \\
  \frac{\chi^{L-1}e^{-\chi/2}}{2^L\Gamma(L)} d\chi &=&  \frac{(e^\Lambda)^{L-1}e^{-e^\Lambda/2}}{2^L\Gamma(L)} e^\Lambda d\Lambda
\end{eqnarray*}
In other words, we have:
\begin{equation}
pdf(\Lambda;L) = \frac{e^{L \Lambda -e^\Lambda/2}}{2^L\Gamma(L)}
\label{eqn:log_chi_square_dist_pdf}
\end{equation}

From the PDF given in Eqn. \ref{eqn:log_chi_square_dist_pdf}, characteristics function can be computed.
By definition, the characteristic function (CF) $\varphi_X(t)$ for a random variable $X$ is computed as:
\begin{eqnarray*}
\varphi_X(t) = \operatorname{E}\big[e^{itX}\big] 
      &=& \int_{-\infty}^\infty e^{itx}\,dF_X(x) \\ 
      &=& \int_{-\infty}^\infty e^{itx} f_X(x)\,dx 
\end{eqnarray*}
with $\varphi_x(t)$ is the characteristic function,
     $F_X(x)$ is the CDF function of X and
     $f_X(x)$ is the PDF function of X.
Thus the characteristic function for log-chi-squared distribution is defined as: 
\begin{equation}
\varphi_\Lambda(t)=\int_0^\infty e^{itx} \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)}\,dx 
\end{equation}

Gamma function is defined over complex domain as:
$\Gamma(z) = \int_0^\infty  e^{-x} x^{z-1} dx .$
Thus $\Gamma(L+it) = \int_0^\infty  e^{-x} x^{L+it-1} dx .$
Set $x=e^z/2$ then $dx=e^z/2dz$, we have $\Gamma(L+it)= \int_0^\infty  e^{itz} \frac{e^{Lz-e^z/2}}{2^{L+it}} dz$
%  \begin{eqnarray*}
%\Gamma(L+it)&=&\int_0^\infty  e^{-e^z/2} (e^z/2)^{L+it-1} e^z/2 dz \\
%  &=& \int_0^\infty  e^{-e^z/2} \frac{e^{z(L+it-1)}}{2^{L+it-1}} e^z/2 dz \\
%  &=& \int_0^\infty  e^{itz} \frac{e^{Lz-e^z/2}}{2^{L+it}} dz
%  \end{eqnarray*}

%Thus the characteristic function becomes
That is:
\begin{equation}
\varphi_\Lambda(t) = 2^{it} \frac{\Gamma(L+it)}{\Gamma(L)}  
\end{equation}

Consequently, the first and second derivative of log-chi-squared distribution can be computed.
The first derivative is given as:
\begin{equation}
  \frac{\partial \varphi_\Lambda(t)}{\partial t} = \frac{i 2^{it} \Gamma(L+it)}{\Gamma(L)} \left[ \ln{2} + \psi^0(L+it) \right]
\end{equation}
due to
\begin{eqnarray*}
  \frac{\partial \Gamma(x)}{\partial x} &=& \Gamma(x)\psi^0(x), \\
  \frac{\partial \Gamma(L+it)}{\partial t} &=& i\Gamma(L+it)\psi^0(L+it), \\
  \frac{\partial 2^{it}}{\partial t} &=& i2^{it}\ln(2), \\
  \partial (u \cdot v) / \partial t &=& u \cdot \partial v /\partial t + v \cdot \partial u/\partial t, 
\end{eqnarray*}
where $\psi^0()$ denotes di-gamma function.

Meanwhile, the second derivative can be written as:
\begin{equation}
  \frac{\partial ^2 \varphi_\Lambda(t)}{\partial t^2} = \frac{i^2 2^{it} \Gamma(L+it)}{\Gamma(L)} \left( \left[ \ln{2} + \psi^0(L+it) \right] ^ 2 + \psi^1(L+it) \right)
\end{equation}
due to:
\begin{eqnarray*}
  \frac{d 2^{it} \Gamma(L+it)}{dt} &=& i 2^{it} \Gamma(L+it) \left[ \ln{2} + \psi^0(L+it) \right], \\
  \frac{d \psi^0(t)}{dt} &=& \psi^1(t), \\
  \frac{d \psi^0(L+it)}{dt} &=& i \psi^1(L+it), \\
  \partial (u \cdot v) / \partial t &=& u \cdot \partial v /\partial t + v \cdot \partial u/\partial t,
\end{eqnarray*}
with $\psi^1()$ denotes tri-gamma function.

The $n^{th}$ moments of random variable $X$ can be computed from the derivatives of its characteristic function as:
\begin{equation}
\operatorname{E}\left(\Lambda^n\right) = i^{-n}\, \varphi_\Lambda^{(n)}(0)
  = i^{-n}\, \left[\frac{d^n}{dt^n} \varphi_\Lambda(t)\right]_{t=0} \,\!
\end{equation}

Thus
\begin{eqnarray*}
 \operatorname{E}\left(\Lambda\right) &=& i^{-1}\, \left[\frac{d\varphi_\Lambda(t)}{dt} \right]_{t=0} \,\! \\
  &=& i^{-1} \left[ \frac{i 2^{it} \Gamma(L+it)}{\Gamma(L)} \left[ \ln{2} + \psi^0(L+it) \right] \right]_{t=0}
% &=& 1/i \left[ \frac{d2^{it} \frac{\Gamma(L+it)}{\Gamma(L)} }{dt} \right]_{t=0} \\
% &=& \frac{1}{\Gamma(L)i} \left[ \Gamma(L+it) \frac{d 2^{it}}{dt} + 2^{it}\frac{d\Gamma(L+it)}{dt} \right]_{t=0} \\
% &=& \left[ \frac{\Gamma(L+it)}{\Gamma(L)i}i2^{it}\ln(2) \right]_{t=0} + \left[ \frac{2^{it}}{\Gamma(L)i}i\Gamma(L+it)\psi^0(L+it) \right]_{t=0} 
\end{eqnarray*}
That is
\begin{equation}
  avg(\Lambda) = \psi^0(L) + ln(2)
\end{equation}

Similarly,
\begin{eqnarray*}
 \operatorname{E}\left(\Lambda^2\right) &=& i^{-2}\, \left[\frac{d^2\varphi_\Lambda(t)}{dt^2} \right]_{t=0} \,\! \\
  &=& \left[ \frac{2^{it} \Gamma(L+it)}{\Gamma(L)} \left( \left[ \ln{2} + \psi^0(L+it) \right] ^ 2 + \psi^1(L+it) \right) \right]_{t=0}  
% &=& -1i \left[ \frac{d \left( \frac{2^{it}\Gamma(L+it)}{\Gamma(L)} (ln2 + \psi^0(L+it)) \right) }{dt}  \right]_{t=0} \\
% &=& \frac{-1i}{\Gamma(L)} \left[ \ln(2) \frac{d 2^{it}\Gamma(L+it)}{dt} + \frac{d 2^{it}\Gamma(L+it)\psi^0(L+it)}{dt}  \right]_{t=0} \\
% &=& + \ln(2) (\psi^0(L)+\ln(2)) - \frac{i}{\Gamma(L)} \left[ \frac{d 2^{it}\Gamma(L+it)}{dt} \psi^0(L+it) + 2^{it}\Gamma(L+it) \frac{d \psi^0(L+it)}{dt} \right]_{t=0}
\end{eqnarray*}
That is:
\begin{equation}
  E(\Lambda^2) = \left[ \psi^0(L)+\ln(2) \right]^2 + \psi^1(L)
\end{equation}
%since $\frac{d\psi^0(x)}{dx}=\psi^1(x)$ then
%$E(X^2) = (\psi^0(L)+\ln(2))(\psi^0(L)+\ln(2)) + \psi^1(L)$.

Thus
\begin{equation}
var(\Lambda)=E(\Lambda^2)-E^2(\Lambda)=\psi^1(L)
\end{equation}

\subsection{Averages and Variances of POLSAR Covariance Matrix Determinant and Log-Determinant}

In this section, the expected value and variance value of these mixture of random variables is derived
\begin{eqnarray}
\chi^d_L &\sim& \prod_{i=0}^{d-1} \chi (2L-2i) \\
\Lambda^d_L &\sim& \sum_{i=0}^{d-1} \Lambda (2L-2i)
\end{eqnarray}
given the averages and variances of individual components.
\begin{eqnarray}
avg \left[ \chi(2L) \right]&=&2L \\
var \left[ \chi(2L) \right]&=&4L \\
avg \left[ \Lambda(2L) \right] &=& \psi^0(L) + \ln2 \\
var \left[ \Lambda(2L) \right] &=& \psi^1(L)
\end{eqnarray}

Making use of the mutual indepent property of each component $X_i$,
  the variance and expectation of the sumation and product of random variables can be written as:
\begin{eqnarray*}
avg \left( \sum^n_{i=1} X_i \right) &=& \sum^n_{i=1} avg(X_i), \\
var \left( \sum^n_{i=1} X_i \right) &=& \sum^n_{i=1} var(X_i), \\
avg \left( \prod^n_{i=1} X_i \right) &=& \prod^n_{i=1} avg(X_i), \\ 
var \left( \prod^n_{i=1} X_i \right) &=& \prod^n_{i=1} \left[ avg^2(X_i) + var(X_i) \right] - \prod^n_{i=1} avg^2(X_i).    
\end{eqnarray*}

Thus they can be computed as:
\begin{eqnarray*}
  avg \left[ \chi^d_L \right] &=& 2^d \cdot \prod^{d-1}_{i=0} (L-i), \\
  var \left[ \chi^d_L \right] &=& \prod^{d-1}_{i=0} 4(L-i)(L-i+1) - \prod^{d-1}_{i=0} 4(L-i)^2, \\
  avg \left[ \Lambda^d_L \right] &=& d \cdot \ln{2} + \sum^{d-1}_{i=0} \psi^0(L-i), \\
  var \left[ \Lambda^d_L \right] &=& \sum^{d-1}_{i=0} \psi^1(L-i)
\end{eqnarray*}

\section{Deriving the Characteristic Functions for the Consistent Measures of Distance}
\label{sec:appendix_b}

Given characteristic function (CF) of the elementary log-chi square distributions can be written as:
\begin{eqnarray}
 CF_{\Lambda(2L)}(t) &=& 2^{it}\Gamma(L+it)/\Gamma(L) \nonumber
\end{eqnarray}
  the CF for the following random variables,
  which are combinations of the above elementary random variables, are to be derived
\begin{eqnarray*}
   \Lambda^d_L &\sim&  \sum^{d-1}_{i=0} \Lambda(2L-2i) \\
  \mathbb{L} &\sim&  \Lambda^d_L -d \cdot \ln(2L) \\
  \mathbb{D} &\sim& \mathbb{L} - d \cdot \ln{L} + \sum^{d-1}_{i=0} \psi^0(L-i) \\
  \mathbb{C} &\sim&  \sum^{d-1}_{i=0} \left[ \Lambda(2L-2i) - \Lambda(2L-2i) \right]
\end{eqnarray*}

Since
\begin{eqnarray*}
 CF_{\sum X_i}(t)   &=& \prod CF_{X_i}(t) \\
 CF_{x+k}(t) &=& e^{itk}CF_x(t)
\end{eqnarray*}
we have:
%\begin{eqnarray}
%\end{eqnarray}
\begin{align}
  CF_{\Lambda^d_L}(t) &= \frac{2^{idt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
   CF_{\mathbb{L}} &= \frac{1}{L^{idt} \Gamma(L)^d}  \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
   CF_{\mathbb{D}} &= \frac{ 1 }{\Gamma(L)^d} \prod^{d-1}_{j=0} e^{idt \psi^0(L-j)} \Gamma(L-j+it)  
\end{align}

%The CF for the contrast random variable can also be written as
Also due to
\begin{eqnarray*}
  CF_{-\Lambda(2L)}(t) &=& 2^{-it}\frac{\Gamma(L-it)}{\Gamma(L)} \\ 
  \Delta(2L) &\sim& \Lambda(2L) - \Lambda(2L) \\
  \Gamma(L-it) \Gamma(L+it) &=&  \Gamma(2L)B(L-it,L+it) \\
   CF_{\Delta(2L)}(t) &=& \frac{\Gamma(2L)B(L-it,L+it)}{\Gamma^2(L)} 
\end{eqnarray*}
we arrive at:
\begin{align}
  CF_{\mathbb{C}} &=&  \prod^{d-1}_{j=0} \frac{\Gamma(2L-2j)B(L-j-it,L-j+it)}{\Gamma^2(L-j)} 
\end{align}
with $\Gamma()$ and $B()$ denotes Gamma and Beta functions respectively.

\section{SAR intensity as the special case of POLSAR covariance matrix determinant}
\label{sec:appendix_sar_special_case_of_polsar}

In this appendix, the following results for SAR intensity $I$ is shown to be special cases of the results given in this paper for the determinant of POLSAR's covariance matrix $det|C_v|$.
Specifically, not only the following results from the our previous works on single-look SAR (TODO:CITE), i.e. $d=L=1$, is reviewed:
\begin{eqnarray}
  I &\sim& \bar{I} \cdot pdf \left[ e^{-R} \right] \\
  \log_2{I} &\sim& \log_2{\bar{I}} + pdf \left[ 2^{D-2^D} \right] \\
  \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ e^{-R} \right]  \\
  \log_2{I} - \log_2{\bar{I}} = \mathbb{D} &\sim& pdf \left[ 2^De^{-2^D}\ln2 \right]\\
  \log_2{I_1} - \log_2{I_2} = \mathbb{C} &\sim& pdf \left[ \frac{2^c}{(1+2^c)^2} \ln2 \right] \\
  avg(\mathbb{D}) &=& -\gamma / \ln{2} \\
  var(\mathbb{D}) &=& \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  mse(\mathbb{D}) &=& \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{eqnarray}
but also the following well-known results for multi-look SAR, i.e. $d=1,L>1$ is also considered:
  \begin{eqnarray}
I &\sim& pdf \left[ \frac{L^L I^{L-1} e^{-LI/\bar{I}}}{\Gamma(L) \bar{I}^L} \right] \\
N = \ln{I} &\sim& pdf \left[ \frac{L^L}{\Gamma(L)} e^{L(N-\bar{N})-Le^{N-\bar{N}}} \right]
  \end{eqnarray}
It will be shown that all of these results are special cases of the result derived previously and rewritten below:
\begin{eqnarray}
  |C_v| &\sim& \frac{|\Sigma_v|}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i)  \label{eqn:polsar_det_cov_dist} \\
  \ln{|C_v|} &\sim& \ln{|\Sigma_v|} + \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \label{eqn:polsar_log_det_cov_dist} 
\end{eqnarray}
\begin{eqnarray}
  \frac{|C_v|}{|\Sigma_v|} = \mathbb{R} &\sim& \frac{1}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i) \label{eqn:polsar_ratio_det_cov_dist} \\
  \ln{|C_v|} - \ln{|\Sigma_v|} = \mathbb{D} &\sim& \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \label{eqn:polsar_dispersion_log_det_cov_dist} \\ 
  \ln{|C_{1v}|} - \ln{|C_{2v}|} = \mathbb{C} &\sim& \sum^{d-1}_{i=0} \Delta(2L-2i)
\end{eqnarray}
\begin{eqnarray}
  avg(\mathbb{D}) &=& \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \label{eqn:polsar_dispersion_averages} \\
  var(\mathbb{D}) &=& \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_variance} \\
  mse(\mathbb{D}) &=& \left[ \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \right]^2 +  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_mse}
\end{eqnarray}

This appendix also derives new results for multi-look SAR data,
  which can be thought of 
    either as extensions of the corresponding single-look SAR results
    or as simple cases of the POLSAR results presented above.
They are:
  \begin{eqnarray}
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& \frac{1}{2L} \chi^2(2L) \\
    \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& \Lambda(2L) - \ln{2L} \\
    \ln{I_1} - \ln{I_2} = \mathbb{C} &\sim& \Delta(2L) \\
    avg(\mathbb{D}) &=& \psi^0(L) - \ln{L} \\
    var(\mathbb{D}) &=& \psi^1(L) \\
    mse(\mathbb{D}) &=& \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
  \end{eqnarray}

The derivation process detailed below consists of two-phases.
The first phase collapse the generic multi-dimensional POLSAR results into the classical one-dimensional SAR domain.
Mathematically this means setting the dimensional number in POLSAR to  $d=1$
  and collapsing the POLSAR covariance matrix into the variance measure in SAR, which also equals the SAR intensity i.e. $|C_v|=I,|\Sigma_v|=\bar{I}$.

The output of the first phase, in the general case is applicable to multi-look SAR data, where $d=1$ but $L>1$.
The second phase simplify the multi-look results into single-look results, presented in our previous work (TODO:CITE).
Mathematically, that means setting $L=1$ in the multi-look result
  and converting from natural logarithmic domain used in this paper to the base-2 logarithm used in (TODO:CITE).

\subsection{Original Domain: SAR Intensity and its ratio}

Setting $d=1$, $|C_v|=I$ and $|\Sigma_v|=\bar{I}$ into Eqns. \ref{eqn:polsar_det_cov_dist} and \ref{eqn:polsar_ratio_det_cov_dist}
we have:
\begin{eqnarray*}
  I &\sim& \frac{\bar{I}}{2L} \chi^2(2L)  \\
  \frac{I}{\bar{I}} = \mathbb{R} &\sim& \frac{1}{2L}  \chi^2(2L)   
\end{eqnarray*}
Or in PDF forms, and applying variable change theorem we have:
\begin{eqnarray*}
    \frac{2L I}{\bar{I}} &\sim& pdf \left[ \frac{x^{L-1}e^{-x/2}}{2^L \Gamma(L)} \right] \\
  \frac{I}{\bar{I}} &\sim& pdf \left[ \frac{x^{L-1}e^{-x/2}}{2^L \Gamma(L)} \cdot dx/dt \right]_{x=2L \cdot t} \\
%    &\sim& pdf \left[ \frac{(2L)^{L-1} t^{L-1} e^{-Lt}}{2^L \Gamma(L)}  \cdot 2L \right] \\
    &\sim& pdf \left[ \frac{ L^{L} t^{L-1} e^{-Lt}}{ \Gamma(L)} \right] \\
  I &\sim& pdf \left[ \frac{ L^{L} t^{L-1} e^{-Lt}}{ \Gamma(L)} \cdot dt/dx \right]_{t=x/\bar{I}}  \\
%    &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L-1}\Gamma(L)} \cdot \frac{1}{\bar{I}} \right] \\
    &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \right]
\end{eqnarray*}

Thus we have the following results for multi-look SAR
\begin{eqnarray}
    I &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{x}}}{ \bar{I}^{L}\Gamma(L)} \right] \label{eqn:multi_look_SAR_intensity_dist} \\
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \label{eqn:multi_look_SAR_ratio_dist} \right] 
\end{eqnarray}

Now setting $L=1$, these results become:
\begin{eqnarray}
    I &\sim& pdf \left[ \frac{ e^{x/\bar{I}}}{ \bar{I}} \right] \\
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ e^{-x} \right] 
\end{eqnarray}
which is the same as in (TODO:CITE).

\subsection{Log-transformed domain: SAR log-intensity and the log-distance}

The result for multi-look SAR data written in log-transformed domain can be derived from two different approaches.
The first is to follow the simplification method, where the results for log-transformed POLSAR data is simplified into log-transformed multi-look SAR result.

The second approach is to apply log-transformation into the results derived in the previous section.
In this section, it is shown that both approaches would results into identical results.

Setting $d=1$, $|C_v|=I$ and $|\Sigma_v|=\bar{I}$ into Eqns. \ref{eqn:polsar_log_det_cov_dist} and \ref{eqn:polsar_dispersion_log_det_cov_dist}
we have
\begin{eqnarray*}
  \ln{I} &\sim& \ln{\bar{I}} + \Lambda(2L) - \ln{2L}  \\
  \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& \Lambda(2L) - \ln{2L} 
\end{eqnarray*}

Or in PDF form, and applying variable change theorem we have:
\begin{eqnarray*}
  \ln{I} - \ln{\bar{I}} + \ln{2L} &\sim& pdf \left[ \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)} \right] \\
  \ln{I} - \ln{\bar{I}} &\sim& pdf \left[ \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)} \cdot dx/dt \right]_{x=t+\ln{2L}} \\
%   &\sim& pdf \left[ \frac{e^{L(t+\ln{2L})-e^{t+\ln{2L}}/2}}{2^L \Gamma(L)}  \right] \\ 
   &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right] \\
  \ln{I} &\sim&  pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)} \cdot dt/dx \right]_{t=x-\ln{\bar{I}}} \\
 &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] 
\end{eqnarray*}
with $\bar{N} = \ln{\bar{I}}$.

Thus the first approach arrives at
\begin{eqnarray}
   \ln{I} = \mathbb{N} &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] \\
   \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right]  
\end{eqnarray}

In the second approach, log-transformation is applied on previous result for multi-look SAR intensity and its ratio in the original domain (Eqns. \ref{eqn:multi_look_SAR_ratio_dist} and \ref{eqn:multi_look_SAR_intensity_dist}).
The also arrives at the same results as above, the details working however is omitted here for brevity.

%\begin{eqnarray*}
%    I &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{x}}}{ \bar{I}^{L}\Gamma(L)} \right] \\
%    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \right] 
%\end{eqnarray*}
%Thus
%\begin{eqnarray*}
%  \ln{I} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \right]_{x=e^t} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{t(L-1)} e^{-Le^t/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \cdot e^t \right]_{\bar{I}=e^{\bar{N}}} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{L(t-\bar{N})} e^{-Le^{t-\bar{N}}}}{ \Gamma(L)}  \right] \\
%  \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \cdot dx/dt \right]_{x=e^t} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{t(L-1)} e^{-Le^t}}{ \Gamma(L)} \cdot e^t \right] \\ 
%      &\sim& pdf \left[ \frac{ L^{L} e^{tL-Le^t} }{ \Gamma(L)}  \right] 
%\end{eqnarray*}
%
%Thus the second approach also arrives at
%\begin{eqnarray}
%   \ln{I} = \mathbb{N} &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] \\
%   \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& pdf \left[ \frac{L^Le^{Lx-Le^x}}{ \Gamma(L)}  \right]  
%\end{eqnarray}

To compute summary statistics for the multi-look SAR dispersion,
  set $d=1$ into the Eqns. \ref{eqn:polsar_dispersion_mse}, \ref{eqn:polsar_dispersion_averages} and \ref{eqn:polsar_dispersion_variance}
we have:
  \begin{eqnarray*}
    avg(\mathbb{L}) &=& \psi^0(L) - \ln{L} \\
    var(\mathbb{L}) &=& \psi^1(L) \\
    mse(\mathbb{L}) &=& \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
\end{eqnarray*}

This completes the first phase of the derivation process.
The second phase of simplification involves setting $L=1$ into the above results for multi-look SAR data,
  and converting natural logarithm into base-2 logarithm.
First, setting $L=1$ makes the above results become
\begin{eqnarray*}
   \ln{I} = \mathbb{N} &\sim&  pdf \left[ e^{(x-\bar{N})-e^{x-\bar{N}}} \right] \\
   \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& pdf \left[ e^{x-e^x}  \right] \\ 
    avg(\mathbb{L}) &=& \psi^0(1) = -\gamma \\
    var(\mathbb{L}) &=& \psi^1(1) = \pi^2 / 6 \\  
    mse(\mathbb{L}) &=& \left[ \psi^0(1) \right]^2 + \psi^1(1) = \gamma^2 + \pi^2 / 6
\end{eqnarray*}
with $\gamma$ denotes the Euler-Mascharoni constant.
Then to convert to base-2 logarithm from natural logarithmic transformation,
  variable change theorem is invoked.
  That is:
  \begin{eqnarray*}
   \log_2{I}  = \mathbb{N}_2    &\sim&  pdf \left[ e^{(x-\bar{N})-e^{x-\bar{N}}} \cdot dx/dt \right]_{x=t\cdot \ln{2}} \\
   \mathbb{N} / \ln{2} = \mathbb{N}_2 &\sim&  pdf \left[ e^{(t\cdot \ln{2}-\bar{N})-e^{t\cdot \ln{2}-\bar{N}}} \ln{2} \right]_{\bar{N}_2 = \bar{N} \cdot \ln{2}} \\
       &\sim&  pdf \left[ 2^{t-\bar{N}_2}e^{2^{t-\bar{N}_2}} \ln{2} \right] 
  \end{eqnarray*}
\begin{eqnarray*}
   \log_2{I} - \log_2{\bar{I}} = \mathbb{L} / \ln{2} = \mathbb{L}_2 &\sim& pdf \left[ e^{x-e^x}  \right]_{x=t \cdot \ln{2}} \\  
%       &\sim& pdf \left[ e^{t \cdot \ln{2}-e^{t \cdot \ln{2}}} \ln{2}  \right] \\
       &\sim& pdf \left[ 2^t e^{2^t} \ln{2}  \right] 
\end{eqnarray*}
\begin{eqnarray*}
  avg(\mathbb{L}_2) &=& avg(\mathbb{L})/ \ln{2} = -\gamma / \ln{2} \\
  var(\mathbb{L}_2) &=& var(\mathbb{L})/ \ln^2{2} = \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  mse(\mathbb{L}_2) &=& mse(\mathbb{L})/ \ln^2{2} = \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{eqnarray*}

\subsection{Deriving the PDF for SAR dispersion and contrast}

The PDF for SAR dispersion can be easily derived from
  the PDF for the Log-distance given above as:
  \begin{equation}
   \ln{I} - avg(\ln{I}) =  \mathbb{D} \sim pdf \left[ \frac{e^{L[x+\psi^0(L)]-Le^{x+\psi^0(L)-\ln{L}}}}{\Gamma(L)} \right]
  \end{equation}
due to $d=1$ and
\begin{eqnarray*}
  \mathbb{D} &\sim& \mathbb{L} - avg(\mathbb{L}) \\
  avg(\mathbb{L}) &=& \psi^0(L) - \ln{L} \\
  \mathbb{L} &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right]
\end{eqnarray*}.

Setting $L=1$ for Single-Look SAR we have
\begin{equation}
  \mathbb{D} \sim pdf \left[ e^{x-\gamma-e^{x-\gamma}} \right]
\end{equation}
due to: $\psi^0(1)=-\gamma$ and $\Gamma(1)=1$
with $\gamma$ being the Euler Mascheroni Constant which equals $0.5772$. 
In base-2 logarithm, variable change theorem is invoked
\begin{eqnarray*}
  \mathbb{D}_2 &=& \log_2{I} - avg(\log_2{I}) = \mathbb{D}/\ln{2} \\
  \mathbb{D}_2 &\sim& pdf \left[ e^{x-\gamma-e^{x-\gamma}} \cdot \frac{dx}{dt} \right]_{x=t \cdot \ln2}
\end{eqnarray*}
Thus we have
\begin{equation}
  \mathbb{D}_2 \sim pdf \left[ e^{-(2^xe^{-\gamma})} (2^xe^{-\gamma}) \ln2 \right]
\end{equation}
which is consistent to the result in our previous work (TODO:CITE).

Setting $d=1$ into Eqn. for contrast result in
\begin{equation}
  \ln{I_1} - \ln{I_2} = \mathbb{C} \sim \Delta(2L)
\end{equation}
The characteristic function would then be
\begin{equation}
  CF_\mathbb{C} =  \frac{\Gamma(2L) B(L-it,L+it)}{\Gamma(L)^2} 
\end{equation}
Thus PDF can be written as
\begin{equation}
  \mathbb{C} \sim pdf \left[ \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{e^{Lx}}{(1+e^x)^{2L}} \right] \label{eqn:multi_look_SAR_contrast_pdf}
\end{equation}
due to
\begin{eqnarray*}
  CF_{\mathbb{C}}(x) &=& \frac{\Gamma(2L) }{\Gamma(L)^2} B(1/(1+e^x),L-it,L+it)  \\
       &=& \frac{\Gamma(2L) }{\Gamma(L)^2} \int^{1/(1+e^x)}_0 z^{L-it-1}(1-z)^{L+it-1} dz \\
  \frac{\partial }{\partial x} CF_{\mathbb{C}}(x) &=&  \frac{\partial CF_{\mathbb{C}}(x) }{\partial 1/(1+e^x)} \cdot \frac{\partial 1/(1+e^x)}{\partial x} \\
%       &=& \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{1}{(1+e^x)^{L-it-1}} \left( \frac{e^x}{1+e^x} \right)^{L+it-1} \frac{1}{(1+e^x)^2} e^x \\
        &=&  e^{itx} \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{e^{Lx}}{(1+e^x)^{2L}}   
\end{eqnarray*}

Setting $L=1$ into Eqn. \ref{eqn:multi_look_SAR_contrast_pdf} 
we have the PDF for contrast of single-look SAR:
\begin{equation}
  \mathbb{C} \sim pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \right]
\end{equation}

Converting to base-2 logarithm we have
\begin{eqnarray*}
  \mathbb{C} / \ln{2} = \mathbb{C}_2 &\sim& pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \cdot dx/dt \right]_{x=t \cdot \ln{2}} \\
%     &\sim& pdf \left[ \ln{2} \frac{e^{t \cdot \ln{2}}}{(1+e^{t \cdot \ln{2}})^{2}}  \right] \\
     &\sim& pdf \left[ \ln{2} \frac{2^t}{(1+2^t)^{2}}  \right] 
\end{eqnarray*}
which is also consistent to the result in our previous work (TODO:CITE).

% references section
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,article}

\end{document}
