%\documentclass[a4paper,10pt]{article}
%ifdef FINAL
\documentclass[journal]{IEEEtran}
%endif
%ifdef REVIEW
\documentclass[journal,12pt,draftcls,onecolumn]{IEEEtran}
%endif
%\documentclass[a4paper, 10pt, conference]{ieeeconf}

\usepackage{cite} %for citations
\usepackage{url}

 %this is for math typing (eg: cases)
\usepackage{amsmath}
   \usepackage{amsfonts}   % if you want the fonts
   \usepackage{amssymb}    % if you want extra symbols
\usepackage{epsfig} %for figures

\usepackage[center]{caption}%for captions
\usepackage[caption=false,font=footnotesize]{subfig} %for subfigures

%\nonstopmode

%opening
\title{
  Homoskedastic Measures of Distance for Heteroskedastic POLSAR Data
%Scalar Homoskedastic Models for POLSAR data
}

%\author{Thanh-Hai Le, Ian McLoughlin}
\author{Thanh-Hai~Le,
        Ian~McLoughlin, 
	and Chan-Hua~Vun%
\thanks{Thanh-Hai~Le and Chan-Hua~Vun are with School of Computer Engineering, 
Nanyang Technological University, Singapore. Ian~McLoughlin is with School of Information Science and Technology,
University of Science and Technology of China.
}% <-this % stops a space
%\thanks{The authors wish to thank Dr. Ken-Yoong Lee and Dr. Timo Brestchneider of EADS Innovation-Works Singapore for 
%	their initial discussions and for providing us the RADAR-SAT2 imagery used in this paper. }% <-this % stops a space
\thanks{Manuscript received ?, 2013; revised ?.}}

\markboth{Transactions on Geoscience \& Remote Sensing,~Vol.~?, No.~?, ?~2013}%
{ Le \MakeLowercase{\textit{et al.}}:  Homoskedastic Measures of Distance for Heteroskedastic POLSAR Data}

\begin{document}

\maketitle

\begin{abstract}
This paper presents a novel homoskedastic and additive model for polarimetric SAR (POLSAR) data. 
The statistical properties of this new model  enable a number of different consistent measures of distance for the POLSAR covariance matrix. 
The dissimilarity measurements, 
computed from the determinant of the POLSAR covariance matrix, are initially developed for both partial (2$\times$2) and full (3$\times$3 monostatic case) polarimetric SAR data.
It is shown that when the multi-polarization POLSAR is collapsed into the single-polarization SAR,
  this covariance matrix determinant is neatly transformed into the traditional SAR intensity.
Thus the SAR intensity statistics can now be considered as a special case of  this new theoretical model for POLSAR.
The statistical model is also robust, and reasonably accurate at describing practical data,
 even  when  the supposedly independent polarimetric components are actually highly correlated (e.g. between $S_{hh}$ and $S_{vv}$).  
Moreover, the match can be further improved 
  if the model validation process includes estimation of the dataset's Effective Number of Looks (ENL) 
  instead of blind acceptance of the number of looks figure reported by the SAR processor.
The application of these dissimilarity measures is demonstrated in this paper for evaluating the effectiveness of POLSAR speckle filters.  
%In this paper, a homoskedastic and additive model for polarimetric SAR (POLSAR) data is introduced. 
%The statistical properties of this model subsequently lead to a few different consistent measures of distance for the POLSAR covariance matrix.
%The dis-similarity measurements are initially developed for both partial (2x2) and full (3x3 monostatic case) polarimetric SAR data.
%They are computed from the determinant of the POLSAR covariance matrix.
%Interestingly, when the multi-polarization POLSAR is collapsed into the single-polarization SAR,
%  this covariance matrix determinant is neatly transformed into the traditional SAR intensity.
%Thus the SAR intensity statistics can now be considered as a special case of the theoretical model for POLSAR.
%While powerful theoretically, the statistical model is also robust in handling practical data.
%It can be validated and match reasonably well with practical data,
% even  when  the supposedly independent polarimetric components are actually highly correlated (e.g. between $S_{hh}$ and $S_{vv}$).
%Moreover, the match can be further improved, as better match is shown achievable, 
%  if the model validation process include an estimation of the dataset's Effective Number of Looks (ENL) 
%  instead of blind employment of the look number given by the SAR processor.
%Towards the end, the practical application of these dissimilarity measures is briefly demonstrated in the context of evaluating POLSAR speckle filters.  
\end{abstract}

\begin{IEEEkeywords}
Polarimetric, Synthetic aperture radar, speckle-filtering, homoskedasticity
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
%\section{POLSAR data: statistical analysis and logarithmic transformation}

In this paper, the POLSAR scattering vector is denoted as $s$.
In the case of partial polarimetric SAR (single polarization in transmit and dual polarization in receipt),
  the vector is two-dimensional ($d=2$) and is normally written as: 
\begin{equation}
s_{part}=\begin{bmatrix}
S_h\\ 
S_v
\end{bmatrix}
\end{equation}
In the case of full and monostatic POLSAR data,
  the vector is three-dimensional ($d=3$) and is presented as:
\begin{equation}
s_{full}=\begin{bmatrix}
S_{hh}\\
\sqrt{2}S_{hv}\\
S_{vv}
\end{bmatrix}
\end{equation}

Let $\Sigma=E [ss^{*T}]$ denote the population expected value of the POLSAR covariance matrix,
  where $s^{*T}$ denotes the complex conjugate transpose of $s$. 
Assuming all the elements in $s$ are independent
  and $s$ is jointly circular complex Gaussian with the given covariance matrix $\Sigma$,
  then the probably density function (PDF) of $s$ can be written as:
\begin{equation}
  pdf(s;\Sigma)=\frac{1}{\pi^d|\Sigma|} e^{-s^{*T}\Sigma^{-1}s}
\end{equation}
where $|M|$ denotes the determinant of the matrix $M$.

As the covariance matrix is only defined on multiple data points,
  sample POLSAR covariance matrices are commonly presented in ``ensemble'' format.
They are formed as the mean of Hermitian outer product of single-look scattering vectors,
\begin{equation}
  C_v = \langle ss^{*T} \rangle = \frac{1}{L} \sum^L_{i=1}s_is_i^{*T}
\end{equation}
where $s_i$ denotes the single-look scattering vector,
  which equals $s_{part}$ in the case of partial POLSAR and
  $s_{full}$ in the case of full polarimetry,
and $L$ is the number of looks.

Complex Wishart distribution statistics, however, are normally written for the scaled covariance matrix
$Z=LC_v$, whose PDF is given as:
\begin{equation}
  pdf(Z;d,\Sigma,L)=\frac{|Z|^{L-d}}{|\Sigma^L|\Gamma_d(L)}e^{-tr(\Sigma^{-1}Z)}
\end{equation}
with $\Gamma_d(L) = \pi^{d(d-1)/2} \prod^{d-1}_{i=0}\Gamma(L-i)$
and $d$ is the dimensional number of the POLSAR covariance matrix.

The approach taken in this paper differs by applying the homoskedastic log transformation  on a less-than-well-known result for the determinant of the covariance matrix.
  %under the assumption of circular complex Gaussian distribution
  %applicable for POLSAR data.
Goodman \cite{Goodman_1963_AMS_178}, %Goodman
proven that the ratio between the observable and expected values of the sample covariance matrix determinants behave like a product of $d$ chi-squared random variables with different degrees of freedom, 
\begin{equation}
\chi^d_L = (2L)^d \frac{|C_v|}{|\Sigma_v|} \sim \prod_{i=0}^{d-1} \chi^2 (2L-2i)
\label{eqn:prod_chi_squared_rv}  
\end{equation}

Its log-transformed variable consequently behaves like a summation of $d$ log-chi-squared random variables with the same degrees of freedom,  
\begin{equation}
\Lambda^d_L = ln \left[ (2L)^d \frac{|C_v|}{|\Sigma_v|} \right] \sim \sum_{i=0}^{d-1} \Lambda^\chi (2L-2i)
\label{eqn:sum_log_chi_squared_rv}
\end{equation}
with
  $\Lambda^\chi (k) \sim \ln \left[ \chi^2 (k) \right]$

In this paper, the above results are exploited in the context of POLSAR data processing. In particular, a few scalar, consistent and homoskedastic measures of distance are proposed. The paper is structured as follows:
  after the preceding introduction to the basics of POLSAR statistical analysis,
  the second section presents evidence for two related points:
(i) POLSAR data is multiplicative and heteroskedastic in its original domain.
(ii) log-transformation converts it into an additive and homoskedastic model.
Consequently a few consistent measures of distance are derived and presented in Section \ref{sec:distance_measure}.
After the model is validated against both partial and full polarimetric SAR data in Section \ref{sec:polsar_models_validation},
  Section \ref{sec:sar_special_case_of_polsar} discusses
    how the proposed models for the multi-variate POLSAR can be used to derive the well-known models for the univariate SAR data as its special case.
Besides being theoretically comprehensive, 
  the model is also shown, in Section \ref{sec:improve_the_match_bw_theory_practice}, to be robust in handling a few practical imperfections that violate conventional assumptions. 
To demonstrate the application of the consistent and homoskedastic dis-similarity measures, 
  Section \ref{sec:evaluating_polsar_filters} explores how they are used for evaluating POLSAR speckle filters.   
Finally, Section \ref{sec:discussion_conclusion} critically reviews and discusses related literature  
  before the paper is concluded in Section \ref{sec:conclusion}.
%Besides being theoretically comprehensive, 
%  the model is also shown, in section \ref{sec:improve_the_match_bw_theory_practice}, to be robust in handling a few practical imperfections that violate conventional assumptions. 
%As an example application of the consistent and homoskedastic dis-similarity measures, 
%  section \ref{sec:evaluating_polsar_filters} explores how they can be used in evaluating POLSAR speckle filters.   
%Finally, section \ref{sec:discussion_conclusion} critically reviews related works in literature 
%  before providing some conclusional discussion. 

\section{Original Hetoroskedastic Domain and the Homoskedastic Log-Transformation}
\label{sec:polsar_heterosked_model_and_log_transform}

In this section the multiplicative nature of POLSAR data is first illustrated.
 Log-transformation is then used to  convert  the data into a more familiar additive model.
%Log-transformation is shown converting this into a more familiar additive model.
Heteroskedasticity, which is defined as the dependence of variance upon the underlying signal,
  is shown to be the case for the original POLSAR data.
In log-transformed domain, the case for a homoskedastic model,
  where sample variance is fixed and thus independent of the underlying signal,
  is also demonstrated.
To keep the section flowing, the mathematical derivation is only presented here in major sketches with more detailed derivation confined to Appendix \ref{chap:appendix_a}.

From Eqns. \ref{eqn:prod_chi_squared_rv} and \ref{eqn:sum_log_chi_squared_rv}
we can deduce the following relationships:
\begin{eqnarray}
  |C_v| &\sim& |\Sigma_v| \cdot \frac{1}{(2L)^d} \cdot \prod_{i=0}^{d-1} \chi^2 (2L-2i) \label{eqn:determinant_distribution} \\
  \ln|C_v| &\sim& \ln|\Sigma_v| - d \cdot \ln(2L) + \sum^{d-1}_{i=0} \Lambda(2L-2i)
\label{eqn:log_determinant_distribution}  
\end{eqnarray}

Within a given homogeneous POLSAR area, parameters $\Sigma_v$, $d$ and $L$ can be considered as constant.
Thus Eqn. \ref{eqn:determinant_distribution} gives the theoretical explaination that: 
  in the original POLSAR domain, a multiplicative speckle noise pattern is present.
At the same time, Eqn. \ref{eqn:log_determinant_distribution} shows that
  the logarithmic transformation has converted this to the more familiar additive noise.  

Since chi-squared random variables $X\ \sim\ \chi^2(k)\ $ follow a known PDF:
\begin{equation}
pdf(x;2L) =
  \frac{x^{L-1} e^{-x/2}}{2^L \Gamma\left(L\right)}
\label{eqn:chi_squared_dist_pdf:chap4}
\end{equation}
applying the variable change theorem, 
  its log-transformed variable follows the PDF of:
\begin{equation}
  pdf(x;2L=k) = \frac{e^{Lx-e^x/2}}{2^{L}\Gamma(L)}
\end{equation}

As the PDFs become available, the characteristic functions (CF) of both the chi-squared and log-chi-squared random variables
  can be found as:
  \begin{eqnarray}
    CF_\chi(t) &=& (1-2it)^{−L} \\ 
    CF_\Lambda(t) &=& 2^{it} \frac{\Gamma(L+it)}{\Gamma(L)} \label{eqn:log_chi_squared_characteristic_function}
  \end{eqnarray}
Subsequently their means and variances can be computed from the given characteristic functions. They are namely:
  \begin{eqnarray}
    avg \left[ \chi(2L) \right]&=&2L \\
var \left[ \chi(2L) \right]&=&4L \\
avg \left[ \Lambda(2L) \right] &=& \psi^0(L) + \ln2 \\
var \left[ \Lambda(2L) \right] &=& \psi^1(L)
  \end{eqnarray}
  where $\psi^0()$ and $\psi^1()$ represent the digamma and trigamma functions respectively.

Since the average and variance of both chi-squared distribution and log-chi-squared distribution are constant,
  the product and summation of these random variables also has fixed summary statistics.
Specifically:
\begin{align*}
  avg \left[ \prod^{d-1}_{i=0} \chi^2(2L-2i) \right] &= 2^d \cdot \prod^{d-1}_{i=0} (L-i), \\
  var \left[ \prod^{d-1}_{i=0} \chi^2(2L-2i) \right] &= \prod^{d-1}_{i=0} 4(L-i)(L-i+1) - \prod^{d-1}_{i=0} 4(L-i)^2, \\
  avg \left[ \sum^{d-1}_{i=0} \Lambda(2L-2i) \right] &= d \cdot \ln{2} + \sum^{d-1}_{i=0} \psi^0(L-i), \\
  var \left[ \sum^{d-1}_{i=0} \Lambda(2L-2i) \right] &= \sum^{d-1}_{i=0} \psi^1(L-i)
\end{align*}

Combining these results with Eqns. \ref{eqn:determinant_distribution} and \ref{eqn:log_determinant_distribution}, we find:
%\begin{eqnarray}
%\end{eqnarray}
\begin{align}
  avg \left[ |C_v| \right]  &= \frac{|\Sigma_v|}{L^d} \prod^{d-1}_{i=0} (L-i)\\
  var \left[ |C_v| \right]  &=   \frac{|\Sigma_v|^2 \left[ \prod^{d-1}_{i=0} (L-i)(L-i+1) - \prod^{d-1}_{i=0} (L-i)^2 \right] }{L^{2d}} \label{eqn:var_det_is_heteroskedastic}\\
  avg \left[ \ln |C_v| \right] &= \ln |\Sigma_v| - d \cdot \ln{L}  + \sum^{d-1}_{i=0} \psi^0(L-i) \label{eqn:avg_log_det} \\
  var \left[ \ln |C_v| \right] &=  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:var_log_det_is_homoskedastic}
\end{align}

For a real world captured image, while the parameters $d$ and $L$ do not change for the whole image,
%Over a real and captured image, while the parameters $d$ and $L$ do not change for the whole image,
  the underlying $\Sigma_v$ is expected to differ from one region to the next.
Thus over a heterogeneous scene, the stochastic process for $|C_v|$ and $\ln |C_v|$ varies depending on the underlying signal $\Sigma_v$. 
In such context, Eqn. \ref{eqn:var_det_is_heteroskedastic} implies that the variance of $|C_v|$ also differs depending on the underlying signal $\Sigma_v$, which indicates its heteroskedastic property.
At the same time, in the log-transformed domain, Eqn. \ref{eqn:var_log_det_is_homoskedastic} reveals that
  the variance of $\ln |C_v|$ is invariant and independent of $\Sigma_v$ manifesting its homoskedastic nature.

\section{Consistent Measures of Distance for POLSAR}
\label{sec:distance_measure}

Similar to the way dispersion and contrast is defined in our previous work \cite{Le_2013_TGRS_SAR_MSE},
  this section introduces the consistent sense of distance from a couple of different perspectives.
Assuming, on the one hand, that the true value of the underlying signal $\Sigma_v$ is known \textit{a priori},
random variables,
  ratio ($\mathbb{R}$) and log-distance ($\mathbb{L}$),
  are observable according to their definitions:
%Eqns. \ref{eqn:prod_chi_squared_rv} and \ref{eqn:sum_log_chi_squared_rv} lead straight to the definition of the following random variables, which is the :
\begin{eqnarray}
  \mathbb{R} &=& \frac{|C_v|}{|\Sigma_v|} \label{eqn:determinant_ratio_observables}\\
  \mathbb{L} &=& \ln|C_v| - \ln|\Sigma_v| \label{eqn:log_distance_observables} 
\end{eqnarray}

On the other hand, under a more forgiving assumption %From another perspective
  where the POLSAR is known to have come from a homogeneous area, but the true value of the underlying signal $\Sigma_v$ is \textit{unknown},
  the dispersion ($\mathbb{D}$) and contrast ($\mathbb{C}$) random variables are observable and they are defined as:
\begin{eqnarray}
  \mathbb{D} &=& \ln{|C_v|} - avg(\ln{|C_v|}) \label{eqn:dispersion_observable}\\
  \mathbb{C} &=& \ln(|C_{v1}|) - \ln(|C_{v2}|) \label{eqn:contrast_observable}
\end{eqnarray}

Using the results from Eqns. \ref{eqn:determinant_distribution}, \ref{eqn:log_determinant_distribution} and \ref{eqn:avg_log_det} we have
\begin{eqnarray}
\mathbb{R} &\sim& \frac{1}{(2L)^d} \cdot \prod_{i=0}^{d-1} \chi^2 (2L-2i) \label{eqn:determinant_ratio_distribution} \\
\mathbb{L} &\sim&  \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln(2L)
\label{eqn:log_determinant_distance_distribution} \\ 
 \mathbb{D} &\sim& \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2} + k
\label{eqn:dispersion_distribution} \\ 
 \mathbb{C} &\sim& \sum^{d-1}_{i=0} \Delta(2L-2i)
\label{eqn:contrast_distribution}  
\end{eqnarray}
with $\Delta(2L) \sim \Lambda(2L) - \Lambda(2L)$
and $k=\sum^{d-1}_{i=0} \psi^0(L-i)$

Also given the characteristic functions (CF) for the elementary components $\Lambda(2L)$ written in Eqn. \ref{eqn:log_chi_squared_characteristic_function}, 
  Appendix \ref{sec:appendix_b} derives the characteristic functions for the summative random variables as:
\begin{align}
  CF_{\Lambda^d_L}(t) &= \frac{2^{idt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\mathbb{L}}(t) &= \frac{1}{L^{idt} \Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\mathbb{D}}(t) &= \frac{e^{ikt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
  CF_{\Delta(2L)} &= \frac{\Gamma(2L) B(L-it,L+it)}{\Gamma(L)^2} \\
  CF_{\mathbb{C}}(t) &=  \prod^{d-1}_{j=0} \frac{\Gamma(2L-2j) B(L-j-it,L-j+it)}{\Gamma(L-j)^2}
\end{align}

Since each elementary %[IVM took out this word]simulation 
component follows fixed distributions (i.e. $\chi^2(2L), \Lambda(2L), ... $),
  it is natural that these variables also follow fixed distributions.
Moreover, they are independent of $\Sigma_v$.
This result shows how
  these random variables follows consistent and fixed distributions,
  regardless of the underlying signal $\Sigma_v$.

\section{Validating the models against real-life data}
\label{sec:polsar_models_validation}

This section describes an experiment to validate the models presented earlier against real-life captured data,
  which can be performed in a rather straightforward manner as follows.
The stochastic models derived in the previous sections can be graphically visualized as histogram plots of the simulated data.
%This section describes an experiment to validate the models above against real-life captured data.
%The validation procedure is quite straightforward.
%Given that the stochastic models have been derived in the previous sections, 
%  they can be graphically visualized by the histogram plots of the simulated data.
At the same time, the form of real-life practical data is also observable via the histogram plots of data samples extracted from a known homogeneous area.
If, for the same parameters, 
  the two plots match each other reasonably well, the theoretical models be can validated to match reality.

For this purpose, a homogeneous area is chosen from the AIRSAR Flevoland POLSAR data [reference?] as experimental data samples, and theoretical models are then created and matched against this data.
%As a demonstration, a homogeneous area was chosen from the AIRSAR Flevoland POLSAR data as experimental data samples.
%Then theoretical models are employed in an attempt to explain the data.
The validating models include:
  the determinant and its log-transformed models, together with the dissimilarity measures namely: the determinant ratio, log-distance, dispersion and the contrast measures of distance.
  
These models are closely related as follows.
For  the same parameter set, the determinant and determinant ratio are simply scaled versions of each other.
Meanwhile, the log-determinant, log-distance and dispersion are also just shifted versions of each other.
Hence one could expect that 
  once a model is validated, the other models in the set will follow suit, 
  assuming that all the parameters of the image are known.% exactly.
Nevertheless, all the models will be separately evaluated in this section.
%The models are closely related.
%Given the same parameter set, the determinant and determinant ratio are just scaled version of each other.
%Meanwhile, the log-determinant, the log-distance and the dispersion are also just shifted version of each other.
%Thus ideally speaking
%  if one model is validated all the other models will also be,
%  assuming that all the parameters of the image are known exactly.
%Still in this section, all the models will be made subject to investigation.

Among the models, the least-assumed stochastic processes for dispersion and contrast measures of distance will be validated first.
For each pixel in the region under test, the determinant of the covariance matrix is computed and the log-transformation is applied.
Then the average of POLSAR covariance matrix’s determinant in the log-transformed domain, i.e. $avg(ln|C_v|)$, is measured for dispersion.
Subsequently the observable samples of dispersion and contrast are computed according to Eqns. \ref{eqn:dispersion_observable} and \ref{eqn:contrast_observable} in order to plot their histograms.

Similarly, theoretical simulations according to Eqns. \ref{eqn:dispersion_distribution} and \ref{eqn:contrast_distribution} are carried out. $L=4$ for this study, while the dimensional number is set to either 3 or 2 depending on whether a full or partial polarimetric SAR dataset is being investigated.
The plots are presented in Fig. 
\ref {fig:verify_polsar_2x2_simulation_dispersion_contrast} showing an evident visual match between the model and real data, thus effectively validating the theoretical models for dispersion and contrast measures of distance.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[part-pol (2x2) dispersion]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_dispersion_distribution.eps} 
		 \label{dispersion_2x2}
	} 
	\hfill	
	\subfloat[part-pol (2x2) contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_contrast_distribution.eps} 	
		 \label{contrast_2x2}
	} \\
	\subfloat[full-pol (3x3) dispersion]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_dispersion_distribution.eps} 
		 \label{dispersion_3x3}
	} 
	\hfill	
	\subfloat[full-pol (3x3) contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_contrast_distribution.eps} 	
		 \label{contrast_3x3}
	}
\end{tabular}
\caption{Validating the dispersion and contrast models against both partial and full polarimetric AIRSAR Flevoland data.}
\label{fig:verify_polsar_2x2_simulation_dispersion_contrast}
\end{figure}

Apart from dispersion and contrast,
the other four models to be investigated require an estimation of the ``true'' underlying signal $|\Sigma_v|$. 
The traditional way to estimate this quantity over an homogeneous area is to simply set the true signal equal to the average of the POLSAR covariance matrix in its original domain, i.e. $\Sigma_v = avg(C_v$).
An alternative approach is to estimate the true signal from the average of the log-determinant of the POLSAR covariance matrix (i.e. $avg[ln|C_v|]$) using Eqn. \ref{eqn:avg_log_det}. For completeness, both approaches will be presented in this section.
As the log-determinant average has already been computed earlier, 
  the second approach will be applied first for the validation of determinant-ratio and log-distance.
%Both approaches will be explored in this section.
%However, given that the log-determinant average has already been computed earlier, 
%  the second approach is used first for the validation of determinant-ratio and log-distance.

Fig. \ref{fig:verify_polsar_2x2_simulation_det_ratio_log_distance} plots the determinant-ratio and log-distance models against real-life data.
In this experiment, the theoretical models are simulated using Eqns \ref{eqn:determinant_ratio_distribution} and
%Fig. \ref{fig:verify_polsar_2x2_simulation_det_ratio_log_distance} validate the models of determinant-ratio and log-distance against real-life data.
%In this experiment, the theoretical models is simulated from Eqns \ref{eqn:determinant_ratio_distribution}
and \ref{eqn:log_determinant_distance_distribution},
  while the observable samples are computed using Eqns \ref{eqn:determinant_ratio_observables} and \ref{eqn:log_distance_observables}
  with the true signal estimated from the log-determinant average, i.e. $avg(\ln|C_v|)$.
%Again a reasonable match is observed which validates the models for log-distance and determinant ratio.  
A reasonable match is again observed which tends to validate the models for log-distance and determinant ratio.   

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[part-pol (2x2) determinant ratio]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_determinant_ratio_distribution.eps} 
		 \label{determinant_ratio_2x2}
	} 
	\hfill	
	\subfloat[part-pol (2x2) log distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_log_distance_distribution.eps} 	
		 \label{log_distance_2x2}
	} \\
	\subfloat[full-pol 3x3 determinant ratio]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_determinant_ratio_distribution.eps} 
		 \label{determinant_ratio_3x3}
	} 
	\hfill	
	\subfloat[full-pol 3x3 log distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_log_distance_distribution.eps} 	
		 \label{log_distance_3x3}
	}
\end{tabular}
\caption{Validating determinant-ratio and log-distance models with $|\Sigma_v|$ is computed using $avg(\ln|C_v|)$}
\label{fig:verify_polsar_2x2_simulation_det_ratio_log_distance}
\end{figure}

Since the models for the determinant and log-determinant are just scaled or shifted version of the models for determinant-ratio and log-distance, similar validation results are to be expected. 
%And if the  true signals are computed in the same manner as described before then in fact similar match can be easily observed. 

However, a more subtle observation phenomena occurs during the validation process for the determinant and its log-transformed model,
%However, a more interesting  phenomena is to be described.
%It happens in the validation process for determinant and its log-transformed model,
  where the theoretical response is taken from the simulated stochastic process described by Eqns. \ref{eqn:determinant_distribution} and \ref{eqn:log_determinant_distribution}.
%For such simulation, an estimation of  the true signal is needed.
The phenomena happens when the true signal is estimated by the first approach i.e. equal to the average of the sample covariance matrix in its original domain (which evidently results in a different estimation for the true signal when compared with the method applied earlier).
%Interestingly, this approach results in a different estimation for the true signal with reference to the method described earlier.

Subsequently the validation plots, which are presented in Fig \ref{fig:verify_polsar_2x2_simulation_det}, exhibit some small translation and scaling discrepancies -- which are
 easier to observe in the log-determinant plots. Despite this, the curve shapes are quite similar.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[verify polsar 2x2: determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_2x2_determinant_distribution.eps} 
		 \label{determinant_2x2}
	} 
	\hfill	
	\subfloat[verify polsar 2x2: log-determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_2x2_log_det_distribution.eps} 	
		 \label{log_det_2x2}
	} \\ 
	\subfloat[verify polsar 3x3: determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/verify_polsar_3x3_determinant_distribution.eps} 
		 \label{determinant_3x3}
	} 
	\hfill	
	\subfloat[verify polsar 3x3: log-determinant]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_polsar_3x3_log_det_distribution.eps} 	
		 \label{log_det_3x3}
	} 
\end{tabular}
\caption{Validating determinant and log-determinant models with $\Sigma_v = avg(C_v)$}
\label{fig:verify_polsar_2x2_simulation_det}
\end{figure}

In summary, the least-assumed dispersion and contrast measures of distance are shown to match reasonably well with the practical data.
The same can be stated for the other four models, namely: determinant, log-determinant, determinant ratio and log-distance,
  if the underlying parameters can be estimated reasonably well for the given image.   
However as described above, a single ``true signal'' $|\Sigma_v|$ can have two different estimated values,
  depending on which estimation method is used.
The discrepancy suggests that at least one of the commonly used methods is slightly incorrect.%IVM - I changed this sentence... please check it!

%But what model parameter were used wrongly, and even if that can be corrected, would a better match become observable?
%The question is answered in Section \ref{sec:improve_the_match_bw_theory_practice}, 
%  where not only the look number is shown to be misused
%  but also the match of between the theoretical model and the practical data is shown to improve as well once a better look number (ENL) is estimated.
As will be shown in Section \ref{sec:improve_the_match_bw_theory_practice}, 
  the reason is due to the inappropriate look number being used.
Furthermore, the match between the theoretical model and the practical data will also be shown to improve once a more accurate look number (ENL) is estimated.  
For now, let us simply observe that
  using appropriate estimation of the parameters, 
  the proposed models match reasonably well with the practical data.

\section{SAR as a Special Case of Polarimetric SAR}
\label{sec:sar_special_case_of_polsar}

The previous section has validated the use of our models for 3-dimensional $d=3$ full polarimetric and two dimensional $d=2$ partial polarimetry cases.
In this section, the model is shown to be also applicable for the 1-dimensional  $d=1$ case.
Physically, this means the multi-dimensional POLSAR dataset is collapsed into one-dimensional classical (conventional?) SAR data.
Mathematically, the sample covariance matrix is reduced to the sample variance
%The prevous section has validated the use of our models for 3-dimensional $d=3$ full polarimetric and two dimensional $d=2$ partial polarimetry cases.
%In this section, the focus is on the case where the dimensional number is reduced to 1 $d=1$.
%Physically this means the multi-dimensional POLSAR dataset is collapsed into the one-dimensional and classical SAR data.
%Mathmatically, the sample covariance matrix is reduced to the sample variance
  and the determinant equates to the scalar value.
On the other hand, it is well known that for SAR data, variance corresponds to intensity.
Thus the special case of our result is investigated carefully and is shown to be consistent with previous results for SAR intensity data.
This can be thought of 
  either as a cross-validation evidence for the proposed POLSAR models
  or alternatively as SAR being simply a special case of POLSAR. 
%  with well known results for SAR intensity is presented.

%The results so far for our models can be summarized as:
The results so far for our models can be summarized using the following equations:
\begin{align}
  \mathbb{R} &= \frac{|C_v|}{|\Sigma_v|} \sim \frac{1}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i) \\% \label{eqn:polsar_ratio_det_cov_dist} \\
  \mathbb{L} &= \ln{|C_v|} - \ln{|\Sigma_v|} \sim \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \\ %\label{eqn:polsar_dispersion_log_det_cov_dist} \\
  \mathbb{D} &= \ln{|C_v|} - avg(\ln{|C_v|}) \sim \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \ln{2} + k\\
  \mathbb{C} &= \ln{|C_{1v}|} - \ln{|C_{2v}|} \sim \sum^{d-1}_{i=0} \Delta(2L-2i) \\
  \mathbb{A} &= avg(\mathbb{L}) = \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \\ %\label{eqn:polsar_dispersion_averages} \\
  \mathbb{V} &= var(\mathbb{L}) = \sum^{d-1}_{i=0} \psi^1(L-i) \\ %\label{eqn:polsar_dispersion_variance} \\
  \mathbb{E} &= mse(\mathbb{L}) =\left[ \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \right]^2 +  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_mse} 
\end{align}

%******************************************************************
%%%IVM:  Hai, you haven't introduced \mathbb{A}, \mathbb{V}, \mathbb{E} in the text, or derived them (although it's pretty simple).
%IVM: maybe just refer the reader back to eqn. 18-21 to get this?
%IVM: Anyway, it does need to be mentioned here and this will also help you
%IVM: to break up the 'pile' of equations here (which is a good thing)
%
%
%******************************************************************

Upon setting $d=1$ into the above equations,
  Appendix \ref{sec:appendix_sar_special_case_of_polsar} shows that the reduced results are consistent with the following two cases.
First is the following results obtained from the our previous works on single-look SAR \cite{Le_2013_TGRS_SAR_MSE}, i.e. $d=L=1$,
%Upon setting $d=1$ into the above models,
%  Appendix \ref{sec:appendix_sar_special_case_of_polsar} shows that the reduced results are consistent with
%not only the following results from the our previous works on single-look SAR \cite{Le_2013_TGRS_SAR_MSE}, i.e. $d=L=1$,
\begin{align*}
  I &\sim \bar{I} \cdot pdf \left[ e^{-R} \right] \\
  \log_2{I} &\sim \log_2{\bar{I}} + pdf \left[ 2^xe^{-2^x}\ln2 \right] \\
  \mathbb{R} &= \frac{I}{\bar{I}} \sim pdf \left[ e^{-x} \right]  \\
  \mathbb{L} &= \log_2{I} - \log_2{\bar{I}} \sim pdf \left[ 2^xe^{-2^x}\ln2 \right]\\
  \mathbb{D} &= \log_2{I} - avg(\log_2{I}) \sim pdf \left[ e^{-(2^xe^{-\gamma})} 2^xe^{-\gamma} \ln2 \right] \\
  \mathbb{C} &= \log_2{I_1} - \log_2{I_2} \sim pdf \left[ \frac{2^x}{(1+2^x)^2} \ln2 \right] \\
  \mathbb{A} &= avg(\mathbb{L}) = -\gamma / \ln{2} \\
  \mathbb{V} &= var(\mathbb{L}) = \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  \mathbb{E} &= mse(\mathbb{L}) = \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{align*}
The second is the following well-known result for multi-look SAR, i.e. $d=1,L>1$:
%but also the following well-known results for multi-look SAR, i.e. $d=1,L>1$:
  \begin{eqnarray}
I &\sim& pdf \left[ \frac{L^L x^{L-1} e^{-Lx/\bar{I}}}{\Gamma(L) \bar{I}^L} \right] \\
N = \ln{I} &\sim& pdf \left[ \frac{L^L}{\Gamma(L)} e^{L(x-\bar{N})-Le^{x-\bar{N}}} \right]
  \end{eqnarray}
Furthermore, the following derivations for multi-look SAR data
   show that it can be thought of 
    either as extensions of the corresponding single-look SAR results
    or as simple cases of the POLSAR results, derived as:
%  Furthermore, the following results for multi-look SAR data,
%  which can be thought of 
%    either as extensions of the corresponding single-look SAR results
%    or as simple cases of the POLSAR results
%  are also derived as:
  \begin{align*}
    \mathbb{R} &= \frac{I}{\bar{I}} \sim pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \label{eqn:multi_look_SAR_ratio_dist} \right]\\
    \mathbb{L} &= \ln{I} - \ln{\bar{I}} \sim pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right] \\
    \mathbb{D} &= \ln{I} - avg(\ln{I}) \sim pdf \left[ \frac{e^{L[x-\psi^0(L)]-e^{[x-\psi^0(L)]}}}{\Gamma(L)} \right] \\
    \mathbb{C} &= \ln{I_1} - \ln{I_2} \sim pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \right] \\
    \mathbb{A} &= avg(\mathbb{L}) = \psi^0(L) - \ln{L} \\
    \mathbb{V} &= var(\mathbb{L}) = \psi^1(L) \\
    \mathbb{E} &= mse(\mathbb{L}) = \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
  \end{align*}

These newly derived models for multi-look SAR data can also be validated against real-life data.
Fig. \ref{fig:verify_multi_look_SAR_dispersion_contrast_models} plots the results of an experiment carried out for the stated purpose.
In this experiment, the intensity of single-channel SAR data (HH) for a known homogeneous area is extracted from the AIRSAR Flevoland dataset.
The histograms for the log-distance and contrast are then plotted with the theoretical PDF given above. In this plot, we set $EN=4$, leading to a reasonably good visual match is apparent.
%Then the histograms for the log-distance and and contrast is plotted against the theoretical PDF given above.
%The ENL is set to the nominal number of 4.
%And good visual match is apparent in the final results.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[verify multi-look SAR log-distance]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_multi_look_sar_dispersion_pdf.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[verify multi-look SAR contrast]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/verify_multi_look_sar_contrast_pdf.eps} 	
		 \label{multi_look_contrast}
	}
\end{tabular}
\caption{Multi-Look SAR dispersion and contrast: modelled response matches well with real-life captured data.}
\label{fig:verify_multi_look_SAR_dispersion_contrast_models}
\end{figure}
      
\section{Handling certain discrepancy between the theoretical model and pratical data}
\label{sec:improve_the_match_bw_theory_practice}

Even though the assumptions made in developing this theory have intentionally been kept minimal, 
  as with other similar models, the proposed model in this paper is built upon certain presumptions and prerequisites.
Practical conditions, however, may not always satisfy those prerequisites.
In this section, certain gaps between the conditions found in real-life data and the theoretical assumptions are discussed.
It is also shown that the theoretical model can apply to the practical data, even in the face of certain ``imperfections''.
%And it is shown that: the theoretical model proposed can handle the practical data, even when these ``imperfections''  are taken into account.

The two main imperfections found in practical POLSAR data are probably those related to the following assumptions:
\begin{enumerate}
\item Each component in the POLSAR target vector $s$ is mutually independent.
\item The samples are statistically independent of each other.
\end{enumerate}

Regarding the first assumption of independent components, it is noted in practice that high correlation is routinely observed at times between the POLSAR data components,
%Practically however high correlation is routinely observable between the POLSAR data components,
  specifically between $S_{hh}$ and $S_{vv}$.
This phenomena is also present in the AIRSAR dataset, where {\scriptsize $\Sigma_v = avg(C_v) = \begin{vmatrix} 0.0084 & 1 \cdot 10^{-6} + 4 \cdot 10^{-4} i & 0.0071 - 0.0017 i \\ 1 \cdot 10^{-6} - 4 \cdot 10^{-4} i & 0.0017 & -3 \cdot 10^{-4} - 2 \cdot 10^{-4} i \\ 0.0071 + 0.0017 i & -3 \cdot 10^{-4} + 2 \cdot 10^{-4} i & 0.0122 \end{vmatrix}$}.
Despite the mismatch,
the astute reader would have noticed that the proposed model is apparently still valid under such condition as evidenced by the part-pol (HH-VV) and full-pol plots in Figs. \ref{fig:verify_polsar_2x2_simulation_dispersion_contrast} to \ref{fig:verify_polsar_2x2_simulation_det}.
This observation suggests that the proposed model is also applicable on correlated POLSAR components, although a full explanation for this is outside the scope of this paper. 
%This suggests that the proposed model is also applicable on correlated POLSAR components,
%  eventhough a full explaination for this, however, is outside the scope of this paper.

The second assumption of statistical independence between samples (which applies to both SAR and POLSAR data) is reasonable given that 
  the transmission and receipt of analogue signals is done independently for each radar pulse, i.e. for each resolution cell.
Thus, theoretically speaking, adjacent pixels in an image can be assumed to be statistically independent.

However, the actual imaging mechanism in a real-life (POL)SAR processor is of a digital nature,
where the analogue signal is to be converted into a digital data-set. 
Specifically, the analogue SAR signal, 
  which is characterised by the pulse bandwidth measurement,
  is fed into an analogue-to-digital (ADC) sampling and conversion process 
  which is characterised by its sampling rate.
Theoretically it may be possible to define a sampling rate that ensures each digital pixel corresponds exactly to an separate analogue physical cell.
Practically however, to ensure ``perfect reconstruction'', the sampling rate is normally set at a slightly higher value than the Nyquist rate, resulting in a higher number of samples per pixel than the number of physical cells available in the scene.  

Stated differently, each physical radar cell in practice may be spread over more than a single pixel, 
resulting in potentially high correlation between neighbouring pixels.
This also results in a in reduction the ENL
  such as when a window of 3$\times$3 pixels, actually contains less than 9 physical analogue cells. 
%It also results in reduced effective number of look, 
%  in which say a window of 3x3 pixel actually contains less than 9 physical analog cells. 
The former phenomena is partially explained in \cite{Raney_1988_TGRS_666} for SAR,
  while the later is experimental observed for POLSAR data in \cite{Lee_1994_TGRS_1017} and \cite{Anfinsen_2009_TGRS_3795}.
The oversampling practice is also documented by the producers of SAR processors.
For AIRSAR, the sampling rate and pulse bandwidth combinations are either 90/40MHz or 45/20MHz \cite{JPL_2013_Web_AIRSAR_Impl}
while for RadarSat2, the pixel resolution and range - azimuth resolutions for SLC fine-quad mode are advertised as $(4.cdot \7 5.1)m^2/(5.2 \cdot 7.7)m^2$ \cite{MDA_2013_Web_RadatSat2_Description}.

%The proposed model can handle this imperfection that is available in pratical data.
In fact, the proposed model can handle this imperfection by estimating and then adopting an ENL value rather than assuming the stated number of looks is correct.
 %the model validation can make use of the Effective Number of Looks that is manually estimated from a given practical dataset.
To investigate further, the following subsections first present a simple ENL estimation technique for POLSAR data, then demonstrate how the practical imperfection manifests itself -- and how it can be handled with a RADARSAT2 dataset example.
We will also illustrate how the match shown in Section \ref{sec:polsar_models_validation} for the AIRSAR Flevoland dataset can be improved by the use of ENL estimation.

\subsection{ENL Estimation}

%IVM: This sub-section describes a few techniques that can be used to estimate the Effective Number of Look (ENL) for a given POLSAR dataset.
%This sub-section describes a few technique to estimate the Effective Number of Look (ENL) for a given POLSAR dataset.
The common approach in ENL estimation is to investigate the summary statistics of a known homogeneous area in the given data
  before making inferences about the inherent ENL.
The summary statistics for $|C_v|$ and $\ln|C_v|$ have been derived in Section \ref{sec:polsar_heterosked_model_and_log_transform},
  where Eqn. \ref{eqn:avg_log_det} indicates that there is a relationship among $|avg(C_v)|,avg(\ln|C_v|),d,L$.
Recall that in carrying out the validation process using AIRSAR Flevoland data with nominal value $L=4$, the relationship was shown to be broken.
The reason is believed to be in the use of inexact value for $L$.
In a given POLSAR datasat, since all values of $|avg(C_v)|,avg(\ln|C_v|),d$ are known,
  it is possible to estimate the ``effective'' number of look, by finding an $L$ that ensures the above relationship is valid.

In fact, this approach was taken in \cite{Anfinsen_2009_TGRS_3795},
  where an equation of the same form as Eqn.  \ref{eqn:avg_log_det} was used to estimate ENL.
Unfortunately, the only known way to solve the equation for the unknown $L$ requires the use of an ``iterative numerical method''.
Instead of relying on the equations for statistical mean to find ENL,
  we propose an approach that makes used of variance statistics in the homoskedastic log-domain to find ENL.
Since the determinant of the POLSAR covariance matrix can be considered as the equivalence of the intensity in SAR data,
  this approach is a generic extension of our previous work on SAR ENL estimation \cite{Le_2013_TGRS_SAR_MSE} for POLSAR data.
Specifically, Eqn. \ref{eqn:var_log_det_is_homoskedastic} can be rewritten as: 
\begin{equation}
  var \left[ ln|C_v| \right] = f(L) = \sum^{d-1}_{i=0} \psi^1(L-i)
  \label{eqn:expected_sample_var_log_as_function_of_enl}
\end{equation}
where $\psi^1()$ again denotes the tri-gamma function.

Theoretically, given some measurable value for $var  \left[ ln|C_v| \right]$, one could iteratively solve the above equation for the unknown $L$.
Practically however, the shape of the right-hand-side can be pre-computed
  and for each computed value of $var  \left[ ln|C_v| \right]$, a corresponding value for $L$ can be found by referencing the variance value on the pre-computed graph or by using an approximation:
%
%
% IVM:  where did you get the equation from? No reference, no derivation!!
%
%
  \begin{equation}
    \hat{L} = d \left( \frac{1}{var(\ln{|C_v|})} + 0.5 \right)
    \label{eqn:enl_estimation_formula}
  \end{equation}
Fig. \ref{fig:plot_enl_var_relation_1x1_and_2x2}
  shows the shapes of the function defined in Eqn. \ref{eqn:expected_sample_var_log_as_function_of_enl} for SAR and partial-POLSAR data $f_{d=1}(L)$ and $f_{d=2}(L)$
  as well as illustrating the simplified approximation formula (Eqn. \ref{eqn:enl_estimation_formula}).
  
\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[ENL and variance log-intensity relations for SAR data]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
                 \epsffile{images/plot_enl_var_relation_1x1.eps} 
		 \label{plot_enl_var_relation_1x1}
	} 
	\hfill	
	\subfloat[ENL and var(log-det) relations for partial POLSAR data]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/plot_enl_var_relation_2x2.eps} 	
		 \label{plot_enl_var_relation_2x2}
	} 
\end{tabular}
\caption{The relation between ENL and sample variance for log-determinant/log-intensity plots}
\label{fig:plot_enl_var_relation_1x1_and_2x2}
\end{figure}

\subsection{Using estimated ENL to better explain practical data}
  
For this experiment an example RADARSAT2 dataset is used, in its Fine-Quad mode Single-Look format.
Nine-look processing is applied before the dispersion histogram in the log-transformed domain is computed for a known homogeneous area.
The histograms for both one-dimensional SAR and two-dimensional partial POLSAR data are plotted in Fig. \ref{fig:handling_radarsat2_oversampling_practice}
  against the theoretical models for the nominal ENL value of 9.
The match, however, is evidently not very close.

A better match can be achieved by first estimating ENL from the observable variance of the log-determinant,
  and the theoretical model is then simulated for the estimated ENL.
Then the new sample histogram is plotted in the same figure,
  showing a much better consistency.
This procedure can always be carried out for a given dataset,
  as long as a homogeneous area can be defined and extracted.
  
\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Handling over-sampling practice in Radarsat2 one-dimensional SAR data (HH)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_radarsat2_oversampling_practice.sar.eps} 	
		 \label{sar}
	} 
	\hfill	
	\subfloat[Handling over-sampling practice in Radarsat2 partial POLSAR data (HH-HV)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_radarsat2_oversampling_practice.part_pol.eps} 	
		 \label{part_pol}
	}   
\end{tabular}
\caption{Nine-look processed Radarsat2 data does not always exhibit nine-look data characteristics. However the homoskedastic model in the log-transformed domain can successfully estimate an effective ENL which matches the data much more closely.}
\label{fig:handling_radarsat2_oversampling_practice}
\end{figure}

Fig. \ref{fig:handling_airsar_oversampling_practice_full_pol} shows that the over-sampling issue is also present in the AIRSAR Flevoland dataset,
  even though it is to a much lesser-extent. %with the nominal 4-look data actually have an effective number-of-look around 3.22 only.
Still, the ``corrected'' ENL offers an evidently better match between the model and real-life data. The mis-match problem appears to depend upon how much over-sampling was used to generate the dataset as well as upon the data dimension.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Handling over-sampling practice in AIRSAR full-pol dataset (contrast better?)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_airsar_oversampling_practice_full_pol_determinant_ratio.eps} 	
		 \label{sar}
	} 
	\hfill	
	\subfloat[Handling over-sampling practice in AIRSAR full-pol dataset]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/handling_airsar_oversampling_practice_full_pol_log_distance.eps} 	
		 \label{part_pol}
	}   
\end{tabular}
\caption{AIRSAR Flevoland also exhibits phenomena of over-sampling practice, through at a lesser extent than the RADARSAT 2 data.}
\label{fig:handling_airsar_oversampling_practice_full_pol}
\end{figure}

\section{Evaluating POLSAR Speckle Filters using consistent measures of distance}
%\section{Visually Evaluating POLSAR Speckle Filters over Heterogeneous Areas}
\label{sec:evaluating_polsar_filters}

Previous sections have developed a model for POLSAR, which is also shown to be applicable to SAR.
In this section, the use of consistent measures of distance in the context of POLSAR speckle filtering are explored briefly.
It has been found \cite{Rignot_1993_TGRS_896} that for SAR data in its original domain,  
   ratio is a better evaluation than standard subtractive residual. 
However, ratio residual is argued as not being natural for digital display \cite{Medeiros_2003_IJRS}.
Our previous work in the context of SAR speckle filtering found that
  in the log-transformed domain, this ratio is transformed into a subtractive residual that is homoskedastic.
  
The variance of sample log-determinant is shown to be linked to the ENL index.
This forms the basis for evaluating POLSAR speckle filters over homogeneous areas.
The procedure is simple:
To evaluate a given POLSAR speckle filter over homogeneous areas,
  the filter is applied over a known homogeneous area and the sample variance of log-determinant is measured.
The Equivant Number of Looks (ENL) is then estimated
  either by referencing prepared graphs from Eqn. \ref{eqn:expected_sample_var_log_as_function_of_enl} 
  or alternatively by setting the measured variance value to $var[\ln{|C_v|}]$ in Eqn. \ref{eqn:enl_estimation_formula}.

In order for such a procedure to be generic,
  it is important that the given POLSAR speckle filter preserve the consistency property in the log-transformed domain.
That can be tested by applying the POLSAR filter into different sets of homogeneous areas and investigating the plots of the dissimilarity measures presented above.
Fig. \ref{fig:boxcar_3x3_preserves_consistency} presents two example plots to show that
  the 3$\times$3 POLSAR boxcar filter preserves the consistency property.
In this case, the boxcar filter is applied to 2 sets of part-pol AIRSAR data over Flevoland (HH-HV and VH-VV).
Log-determinant and the contrast measures are computed for the input and output filtered POLSAR data,
  and their plots are presented.
In fact, the test procedure can be applied on any of the models presented above.  

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Log-determinant histograms of boxcar 3$\times$3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/boxcar_3x3_preserves_consistency.log_determinant.eps} 	
		 \label{log_determinant}
	} 
	\hfill	
	\subfloat[Contrast histograms of boxcar 3$\times$3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/boxcar_3x3_preserves_consistency.contrast.eps} 	
		 \label{contrast}
	}   
\end{tabular}
\caption{POLSAR 3$\times$3 boxcar filter preserves the consistency property. Consistency means: as long as the area is homogeneous, regardless of the underlying signal $\Sigma_v$, the shapes of the histograms should match.}
\label{fig:boxcar_3x3_preserves_consistency}
\end{figure}

The consistency property of a POLSAR speckle filter is important
  not only to make the estimation of ENL become general enough.
It is also to ensure that any classification / detection algorithm
    which is based on the scalar and consistent measures of distance will work on both pre-filtered and post-filtered data.
Otherwise if a POLSAR speckle filter gives different plots for different homogeneous areas,
  then not only its ENL estimation will be dependent on the underlying signal, 
  but its output also shall not follow the statistical distribution family that characterises multi-look POLSAR.
Thus the preservation of this consistency is believed to be an important consideration for POLSAR speckle filters
  if we want many general detection and classification algorithms to work on the filtered data output.

In evaluation over heterogeneous area, the consistent measures of distance may also be an invaluable tool.
 %in helping to evaluate POLSAR speckle filters.
Firstly, since the model for log-determinant is additive and homoskedastic,
  log-determinant images may naturally be better suited for gray-level digital display.
Specifically for evaluation of statistical estimators, it is both important and convenient to investigate the estimators' error / residual image. %plays an important role.

For further analysis, the residual is defined here as the distance between the log-determinants of the filtered outputs and the original input. 
Ideally speaking, under the context of an additive model,
  a perfect estimators residual should consist only of random noise.
And under the assumption of homoskedasticity, 
  the Gauss Markov theorem becomes applicable.
Thus the optimal estimator is expected to exhibit minimal Mean Squared Error (MSE).
Over a homogeneous scene, this is reflected in the expectation of minimal bias and variance (hence maximal ENL).
Over a heterogeneous scene, where the underlying signal is not known \textit{a priori},
  the second best gauge is possibly to have the residual MSE being as close as possible to the MSE of the inherent noise.
  
To illustrate the above analysis, an experiment is carried out to evaluate the performance of 3$\times$3 and5$\times$5 boxcar POLSAR filters on the AIRSAR Flevoland partial polarimetric data (HH-HV).
A square 700$\times$700 pixel patch is extracted from the AIRSAR dataset,
  and the two POLSAR speckle filters applied to the patch.
Then the log-determinant images of the filtered outputs are displayed in Fig. \ref{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5}.
At the same time, the residual is computed for both filters, and the images are also displayed in the same figure.
Assuming the quantitative evaluation of SAR speckle filters can also be extended to POLSAR speckle filters,
  the Mean Squared Error (MSE) of the filters residuals are computed and compared with the ``optimal'' value.
This optimal value is found   
by setting $d=2,L=4$ into Eqn. \ref{eqn:polsar_dispersion_mse} making the expected MSE being $mse(\mathbb{L})=1.0132$.

\begin{figure}[h]
\centering
\begin{tabular}{c}
	\subfloat[Log-determinant Image of boxcar 3$\times$3 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_3.filtered.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[Log-determinant Image of boxcar 5$\times$5 speckle filter]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_5.filtered.eps} 	
		 \label{multi_look_contrast}
	} \\
	\subfloat[Image of Log-determinant Residual for 3$\times$3 filter (MSE=1.5594)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_3.residual.eps} 	
		 \label{multi_look_dispersion}
	} 
	\hfill	
	\subfloat[Image of Log-determinant Residual for 5$\times$5 filter (MSE=2.1420)]{
		 \epsfxsize=1.5in
		 \epsfysize=1.5in
		 \epsffile{images/visual_eval_part_pol_boxcar_5.residual.eps} 	
		 \label{multi_look_contrast}
	} 
\end{tabular}
\caption{Visually Evaluating POLSAR Boxcar 3$\times$3 vs. 5$\times$5 Speckle Filters on AIRSA Flevoland part-pol data (HH-HV) with expected MSE=1.0312 at ENL=4. }
\label{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5}
\end{figure}
%Note if the picture does not look convincing enough
%another option here is to show 7x7 filter with more pronouced blurring MSE=2.5

Fig. \ref{fig:visual_eval_part_pol_boxcar_speckle_filters_3x3_vs_5x5} shows that not only does the log-determinant image offer a nice visualization of the scene, 
  but also the distortion impact of the filter can also be made visible by the residual image.
In visual evaluation, while it is quite hard to observe the worsening blurring-effects of the boxcar 5$\times$5 speckle filter as compared to the 3$\times$3 filter
in the additive log-determinant image of the filtered output, 
  such a conclusion can be made relatively easier by visualising the residual image.

When quantified evaluation is carried out
  where the residual MSE is compared with the expected level of noise to be removed,
  the excessive blurring effects of the 5$\times$5 filter become clearly evident.
%IVM: [cut this]In fact, even the 3$\times$3 boxcar filter itself might be also a bit blurry.
%,  as suggested by its relatively high residual values.
%A conclusion which is hard to make
It may be hard to make such a conclusion just by looking at the filtered imagery.
However, by investigating the residual between the unfiltered input and the filtered results in the additive and homoskedastic model, both visual and quantitative evaluations offer more conclusive evidence.

Further discussion on the specific topic of evaluating SAR speckle filters is given in our previous work \cite{Le_2013_TGRS_SAR_MSE}.
However, due to space restriction, only a brief and critical exploration is explored here for POLSAR speckle filters (i.e. extending the previous SAR approach).

Specifically, this is an illustration of how the proposed theoretical model can possibly be applied to a practical scenario, rather than a full evaluation procedure and methodology.
%IVM [cut this],  as it is not as a full proposal for such an evaluation procedure for POLSAR speckle filters.

\section{Discussion and Conclusion}
\label{sec:discussion_conclusion}

\subsection{Related Work in Literature}
%IVM: [cut] This sub-section reviews some relevant and published works on proposing different measures of distance for POLSAR data. 
A few different matrix distances have been proposed and evaluated in recent review papers\cite{Dabboor_2013_IJRS_1492}\cite{Kersten_2005_TGRS_519}, and these
will be discussed in the light of the approach proposed in this paper.
%specifically a few different matrix distances have been proposed and evaluated in recent review papers\cite{Dabboor_2013_IJRS_1492}\cite{Kersten_2005_TGRS_519}

The commonly used measure of distance for matrices are either the Euclidean or the Manhattan distances, as follows:
\begin{align}
  d(C_x,C_y) &= \sum_{i,j} |\mathbb{R} (C_x - C_y)_{i,j}| + \sum_{i,j} |\mathbb{I} (C_x - C_y)_{i,j}| \\
  d(C_x,C_y) &= \sqrt{\sum_{i,j} |C_x - C_y|_{i,j}^2 }
\end{align}
where $A_{i,j}$ denotes the (i,j) elements of matrix A,
 $|.|$ denotes absolute values
and $\mathbb{R},\mathbb{I}$ denote the real and imaginary parts respectively.
However, in the context of POLSAR covariance matrix, they are not widely used, given the multiplicative nature of the data.
%In the context of polsar covariance matrix, however, they are not widely used 
%  probably because of the multiplicative nature of the data.

In the field of POLSAR, the Wishart Distance is probably the most widely used as part of the well-known Wishart Classifier \cite{Lee_1999_TGRS}.
The distance is defined as \cite{Lee_1994_IJRS_2299}:
\begin{equation}
  d(C_x,C_y) = \ln|C_y| + tr(C_xC_y^{-1})
\end{equation}
As a measure of distance, its main disadvantage is that $d(C_y,C_y) = \ln|C_y| \neq 0$.

Recent works have suggested a number of other dissimilarity measures including
the asymmetric and symmetric refined Wishart distances\cite{Anfinsen_2007_ESA_POLINSAR},
\begin{align}
  d(C_x,C_y) &= \frac{1}{2} tr(C_x^{-1}C_y + C_y^{-1}C_x) - d \\
    d(C_x,C_y) &= \ln|C_x| - \ln|C_y| + tr(C_xC_y^{-1}) - d
\end{align}
the Bartlett distance\cite{Kersten_2005_TGRS_519},
  \begin{align}
  d(C_x,C_y) &= 2 \ln |C_{x+y}| - \ln |C_x| - \ln |C_y| - 2d\ln2
  \end{align}
the Bhattacharyya distance\cite{Lee_2011_IGARSS_3740},
\begin{equation}
  r(C_x,C_y) = \frac{|C_x|^{1/2} |C_y|^{1/2}}{|(C_x+C_y)/2|}
\end{equation}
and the Wishart Statistical test distance\cite{Cao_2007_TGRS_3454},
\begin{equation}
  d(C_x,C_y) = (L_x + L_y) \ln|C| - L_x \ln|C_x| - L_y\ln|C_y|
\end{equation}


In comparison to these formula, the distance measure for two covariance matrices proposed in this paper can be summarised as:
\begin{equation}
  d(C_x,C_y) =  \ln|C_x| - \ln|C_y| 
\end{equation}
At first glance, while the proposed formula may be a lot simpler, it is still very similar to others in making use of the log-determinant.

Closer investigation of the dissimilarity measures mentioned reveals that most of them are related to each other.
The Bhattacharyya distance is easily shown to be related to the Barlett distance.
At the same time the Barlett distance can be considered as a special case of the Wishart Statistical Test distance, where the two data sets have the same number of looks $L_x=L_y$.
It is also intuitively trivial to arrive at the conclusion that the contrast measure of distance proposed in this paper have fixed statistical behaviour just by comparing the symmetric and asymmetric versions of the refined Wishart distance, assuming that they are shown to follow fixed distributions.

The close relation among these is further supported by the fact that
all of the mentioned works referenced the statistical model developed in \cite{Conradsen_2003_TGRS_4} as their foundation.
Interestingly, the change detection model also make use of determinant ratio and log determinant in its derivation.  
The next sub-section will illustrate how the log-determinant model presented in this paper can offer an alternative and simple derivation for the change-detection statistics.
  
\subsection{The Likelihood Test Statistics for POLSAR}

To determine if the two scaled multi-look POLSAR covariance matrices $Z_x$ and $Z_y$,
  which have $L_x$ and $L_y$ as the corresponding number of looks,
  come from the same underlying stochastic process,
the likelihood ratio statistics for POLSAR covariance matrices is considered \cite{Conradsen_2003_TGRS_4}:
\begin{equation}
  Q = \frac{(L_x+L_y)^{d \cdot (L_x+L_y)}}{L_x^{d \cdot L_x} L_y^{d \cdot L_y}} \frac{|Z_x|^{L_x} |Z_y|^{L_y} }{|Z_x+Z_y|^{(L_x+L_y)}}
\end{equation}

Taking the log-transformation of the above statistics, and noting that $C_{vx} = Z_x / L_x$, $C_{vy} = Z_y / L_y$ and $C_{vxy} = (Z_x + Z_y)/(L_x + L_y)$ it can be rewritten as:
\begin{eqnarray}
  Q &=& \frac{|C_{vx}|^{L_x} \cdot |C_{vy}|^{L_y} }{|C_{vxy}|^{L_x + L_y}} \nonumber \\
  \ln Q &=& L_x \ln |C_{vx}| + L_y \ln |C_{vy}| - (L_x + L_y) \ln |C_{vxy}| \nonumber
\end{eqnarray}

To detect changes, a test statistics is developed based on this measure of distance.
This means a distribution is to be derived for the dissimilarity measure.
However, originally in the proposed work, only an asymptotic distribution is derived.
In this sub-section, a statistical model is developed for this measure of distance.

Since both $Z_x$ and $Z_y$ follow complex Wishart distribution with $L_x$ and $L_y$ degrees of freedom,
  $Z_x+Z_y$ also follows the complex Wishart distribution with $L_x + L_y$ degrees of freedom.
In view of the models denoted in Eqn. \ref{eqn:log_determinant_distribution},
  it is evident that not only the bound for $\ln Q$, or equivalently $Q$, can be derived
  but the whole statistical distribution for it can be modelled as well:
%\begin{eqnarray}
%  Q &\sim& \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y} \cdot (2(L_x+L_y))^{d (L_x + L_y)}}{(2 L_x)^{d \cdot L_x} \cdot (2 L_y)^{d \cdot L_y} (\chi^d_{L_x + L_y})^{L_x + L_y}} \\
%    &=& \frac{(L_x+L_y)^{d (L_x + L_y)}}{(L_x)^{d \cdot L_x} \cdot (L_y)^{d \cdot L_y} } \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y}}{(\chi^d_{L_x + L_y})^{L_x + L_y}} \\
%\end{eqnarray}
\begin{align*}
  \ln{Q} &\sim  k + L_x \Lambda^d_{L_x} + L_y \Lambda^d_{L_y} - (L_x + L_y) \Lambda^d_{(L_x + L_y)} \\
  Q &\sim e^k \frac{(\chi^d_{L_x})^{L_x} \cdot (\chi^d_{L_y})^{L_y}}{(\chi^d_{L_x + L_y})^{L_x + L_y}}   
\end{align*}
where $k = d \left[ (L_x + L_y) \ln(L_x + L_y) - L_x \ln{L_x} - L_y \ln{L_y} \right]$.

In the common case of $L_x = L_y$, the test statistics become
$\ln Q = \ln |C_{vx}| + \ln |C_{vy}| - 2 |\ln C_{vxy}|$.
This and the Barlett distance introduced earlier are closely related, in fact they are simply shifted versions of each other.
Under exactly the same assumptions, 
  the contrast model which is written as $\mathbb{C} = \ln C_{vx} - \ln C_{vy}$ and presented above should provide another consistent and equivalent approach,
  with potentially a simpler conceptual model and reduced computational requirements. 
%a slightly simpler statistics.

\subsection{Discussion}

Let us begin the discussion by noting a few theoretical properties of the proposed statistical model.
First, the use of covariance matrix log-determinant may be related to the standard eigen-decomposition method of the POLSAR covariance matrices.
In fact, the log-determinant can also be computed as the sum of log-eigenvalues.
Specifically $\ln{|M|} = \sum \ln{\lambda_M}$ where $\lambda_M$ denotes all the eigenvalues of M.
Thus similar to other eigenvalue based approach (e.g. entropy/anisotropy, ...),
  the models presented here are invariant to polarization basis transformations.

Second, the model is developed for the POLSAR covariance matrix.
However, since the POLSAR coherent matrix is related with the covariance matrix via an unitary transformation, which preserves the determinant as invariant,
the model should also be applicable on the coherency matrix.

The model is far from complete.
 It calls for the reduction of the multi-dimensional POLSAR data into a scalar value.
While this is probably desirable for a wide range of application where a one-dimensional number is required to represent the complex multi-dimensional data,
  such a reduction is unlikely to be lossless.
Thus is very similar to the way the Wishart Classifier is employed, and thus to better understand POLSAR data
  the use of this technique can be complemented with some high-dimensional POLSAR target-decomposition techniques (e.g. the Freeman Durden decomposition \cite{Freeman_1998_TGRS_963} or the entropy/anisotropy decomposition \cite{Cloude_1997_TGRS_68} ...).

However the model as presented is promising. Those presented in this paper were first developed for partial and monostatic POLSAR data.
They were then shown to be also applicable to traditional SAR data.
Since the models assumptions are quite minimal, they may also be found to apply to bi-static and interferometric data, although that would require significant further investigations.
%Other interesting phenomena which may warrant more study include the applicability of the model on correlated polsar channels ($S_{hh},S_{vv}$) as well as a better explanation in the use of mse to evaluate polsar speckle filters.

Several practical applications may be developed using the model presented here and its derivatives.
First, the model allow for the estimation and simulation of a non-natural equivalent number of looks (ENL).
This is especially useful when real-life data is available for which the effective number of looks may not equal the nominal stated number-of-look, after multi-look-processing.
In such cases, better-matching models can be derived
  by estimating the effective ENL first (although this usually results in a non-integer result).

Similar to the way that other measures of distance can be used to derive POLSAR classifiers \cite{Lee_1999_TGRS}, change detectors \cite{Conradsen_2003_TGRS_4}, edge detectors \cite{Schou_2003_TGRS_20} or other clustering and speckle filtering techniques \cite{Le_2010_ACRS} \cite{Le_2011_ACRS}, 
new detection, classification, clustering or speckle filtering algorithms can be derived using the models presented in this paper.
Since extensive examples have been shown to support the use of MSE for SAR data,
  it is reasonable to expect the relevance of MSE to also be demonstrated for POLSAR data.
If that is the case, a large number of existing algorithms can become applicable to the POLSAR model in this log-transformed domain,
  which has been shown to be both additive and homoskedastic.   

\section{Conclusion}
\label{sec:conclusion}

An additive and homoskedastic model, 
  which results in several scalar and consistent measures-of-distance for multi-variate POLSAR data
  is proposed in this paper.
The theoretical model is shown to be comprehensive:
not only it can provide alternative and sometimes simpler explanations to a range of theoretical concepts such as POLSAR test statistics or ENL estimation, 
it also potentially makes several well-known models for traditional SAR become applicable for POLSAR processing.  %IVM: <- changed this sentence, please check.

The statistical model proposed in this paper is based on the determinant of the POLSAR covariance matrix  which, when converted into one-dimensional data,
  is gracefully transformed into traditional SAR intensity.
Consequently, the derived dissimilarity measures may be employed in a wide range of applications where a scalar number is required to represent the complex multi-dimensional POLSAR data.
The model is also shown to be practically versatile and capable of handling two common imperfections found in practical data.   As an application of the model,
  as well as an extension of our previous work on evaluating SAR speckle filters\cite{Le_2010_ACRS},
  the application of these additive and homoskedastic distances in the context of evaluating POLSAR speckle filters is briefly explored with promising initial results presented.  
  


















\appendices
\section{Homoskedastic Model for the Log-Determinant}
\label{chap:appendix_a}

\subsection{Log-Chi-Square Distribution and its Derivatives}
%\section{Log-Chi-Square Distribution}
\renewcommand{\theequation}{\thesection.\arabic{equation}}
\setcounter{equation}{0}

This section provides the mathematical derivations for the log-transformed version of chi-squared random variables.

Chi-squared random variables $\chi\ \sim\ \chi^2(k)\ $ follows the pdf:
\begin{equation}
pdf(\chi;\,k) =
  \frac{\chi^{(k/2)-1} e^{-\chi/2}}{2^{k/2} \Gamma\left(\frac{k}{2}\right)}  
\label{eqn:chi_squared_dist_pdf:appdixA}
\end{equation}

Setting L=k/2 into Eqn. \ref{eqn:chi_squared_dist_pdf:appdixA}
\begin{equation}
pdf(\chi) = \frac{\chi^{L-1}e^{-\chi/2}}{2^L\Gamma(L)}
\end{equation}

Applying the variable change theorem, which states that: if $y=\phi(x)$ with $\phi(c)=a$ and $\phi(d)=b$, then:
\begin{equation}
 \int_a^b \! f(y) \, dy = \int_c^d \! f[\phi(x)] \frac{d\phi}{dx} dx
\end{equation}
into the log-transformation, which changes the random variables $\Lambda=ln(\chi)$, we have:
\begin{eqnarray*}
  d\chi &=& e^\Lambda d\Lambda \\
  \frac{\chi^{L-1}e^{-\chi/2}}{2^L\Gamma(L)} d\chi &=&  \frac{(e^\Lambda)^{L-1}e^{-e^\Lambda/2}}{2^L\Gamma(L)} e^\Lambda d\Lambda
\end{eqnarray*}
In other words, we have:
\begin{equation}
pdf(\Lambda;L) = \frac{e^{L \Lambda -e^\Lambda/2}}{2^L\Gamma(L)}
\label{eqn:log_chi_square_dist_pdf}
\end{equation}

From the PDF given in Eqn. \ref{eqn:log_chi_square_dist_pdf}, a characteristic function can be computed.
By definition, the characteristic function (CF) $\varphi_X(t)$ for a random variable $X$ is computed as:
\begin{eqnarray*}
\varphi_X(t) = \operatorname{E}\big[e^{itX}\big] 
      &=& \int_{-\infty}^\infty e^{itx}\,dF_X(x) \\ 
      &=& \int_{-\infty}^\infty e^{itx} f_X(x)\,dx 
\end{eqnarray*}
with $\varphi_x(t)$ is the characteristic function,
     $F_X(x)$ is the CDF function of X and
     $f_X(x)$ is the PDF function of X.
Thus the characteristic function for the log-chi-squared distribution is defined as: 
\begin{equation}
\varphi_\Lambda(t)=\int_0^\infty e^{itx} \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)}\,dx 
\end{equation}

The Gamma function is defined over the complex domain as:
$\Gamma(z) = \int_0^\infty  e^{-x} x^{z-1} dx .$
Thus $\Gamma(L+it) = \int_0^\infty  e^{-x} x^{L+it-1} dx .$
Set $x=e^z/2$ then $dx=e^z/2dz$, we have $\Gamma(L+it)= \int_0^\infty  e^{itz} \frac{e^{Lz-e^z/2}}{2^{L+it}} dz$
%  \begin{eqnarray*}
%\Gamma(L+it)&=&\int_0^\infty  e^{-e^z/2} (e^z/2)^{L+it-1} e^z/2 dz \\
%  &=& \int_0^\infty  e^{-e^z/2} \frac{e^{z(L+it-1)}}{2^{L+it-1}} e^z/2 dz \\
%  &=& \int_0^\infty  e^{itz} \frac{e^{Lz-e^z/2}}{2^{L+it}} dz
%  \end{eqnarray*}

%Thus the characteristic function becomes
That is:
\begin{equation}
\varphi_\Lambda(t) = 2^{it} \frac{\Gamma(L+it)}{\Gamma(L)}  
\end{equation}

Consequently, the first and second derivative of the log-chi-squared distribution can be computed.
The first derivative is given as:
\begin{equation}
  \frac{\partial \varphi_\Lambda(t)}{\partial t} = \frac{i 2^{it} \Gamma(L+it)}{\Gamma(L)} \left[ \ln{2} + \psi^0(L+it) \right]
\end{equation}
due to
\begin{eqnarray*}
  \frac{\partial \Gamma(x)}{\partial x} &=& \Gamma(x)\psi^0(x), \\
  \frac{\partial \Gamma(L+it)}{\partial t} &=& i\Gamma(L+it)\psi^0(L+it), \\
  \frac{\partial 2^{it}}{\partial t} &=& i2^{it}\ln(2), \\
  \partial (u \cdot v) / \partial t &=& u \cdot \partial v /\partial t + v \cdot \partial u/\partial t, 
\end{eqnarray*}
where $\psi^0()$ denotes the di-gamma function.

Meanwhile, the second derivative can be written as:
\begin{equation}
  \frac{\partial ^2 \varphi_\Lambda(t)}{\partial t^2} = \frac{i^2 2^{it} \Gamma(L+it)}{\Gamma(L)} \left( \left[ \ln{2} + \psi^0(L+it) \right] ^ 2 + \psi^1(L+it) \right)
\end{equation}
due to:
\begin{eqnarray*}
  \frac{d 2^{it} \Gamma(L+it)}{dt} &=& i 2^{it} \Gamma(L+it) \left[ \ln{2} + \psi^0(L+it) \right], \\
  \frac{d \psi^0(t)}{dt} &=& \psi^1(t), \\
  \frac{d \psi^0(L+it)}{dt} &=& i \psi^1(L+it), \\
  \partial (u \cdot v) / \partial t &=& u \cdot \partial v /\partial t + v \cdot \partial u/\partial t,
\end{eqnarray*}
with $\psi^1()$ denotes the tri-gamma function.

The $n^{th}$ moments of random variable $X$ can be computed from the derivatives of its characteristic function as:
\begin{equation}
\operatorname{E}\left(\Lambda^n\right) = i^{-n}\, \varphi_\Lambda^{(n)}(0)
  = i^{-n}\, \left[\frac{d^n}{dt^n} \varphi_\Lambda(t)\right]_{t=0} \,\!
\end{equation}

Thus
\begin{eqnarray*}
 \operatorname{E}\left(\Lambda\right) &=& i^{-1}\, \left[\frac{d\varphi_\Lambda(t)}{dt} \right]_{t=0} \,\! \\
  &=& i^{-1} \left[ \frac{i 2^{it} \Gamma(L+it)}{\Gamma(L)} \left[ \ln{2} + \psi^0(L+it) \right] \right]_{t=0}
% &=& 1/i \left[ \frac{d2^{it} \frac{\Gamma(L+it)}{\Gamma(L)} }{dt} \right]_{t=0} \\
% &=& \frac{1}{\Gamma(L)i} \left[ \Gamma(L+it) \frac{d 2^{it}}{dt} + 2^{it}\frac{d\Gamma(L+it)}{dt} \right]_{t=0} \\
% &=& \left[ \frac{\Gamma(L+it)}{\Gamma(L)i}i2^{it}\ln(2) \right]_{t=0} + \left[ \frac{2^{it}}{\Gamma(L)i}i\Gamma(L+it)\psi^0(L+it) \right]_{t=0} 
\end{eqnarray*}
That gives the result:
\begin{equation}
  avg(\Lambda) = \psi^0(L) + ln(2)
\end{equation}

Similarly, for the second moment,
\begin{eqnarray*}
 \operatorname{E}\left(\Lambda^2\right) &=& i^{-2}\, \left[\frac{d^2\varphi_\Lambda(t)}{dt^2} \right]_{t=0} \,\! \\
  &=& \left[ \frac{2^{it} \Gamma(L+it)}{\Gamma(L)} \left( \left[ \ln{2} + \psi^0(L+it) \right] ^ 2 + \psi^1(L+it) \right) \right]_{t=0}  
% &=& -1i \left[ \frac{d \left( \frac{2^{it}\Gamma(L+it)}{\Gamma(L)} (ln2 + \psi^0(L+it)) \right) }{dt}  \right]_{t=0} \\
% &=& \frac{-1i}{\Gamma(L)} \left[ \ln(2) \frac{d 2^{it}\Gamma(L+it)}{dt} + \frac{d 2^{it}\Gamma(L+it)\psi^0(L+it)}{dt}  \right]_{t=0} \\
% &=& + \ln(2) (\psi^0(L)+\ln(2)) - \frac{i}{\Gamma(L)} \left[ \frac{d 2^{it}\Gamma(L+it)}{dt} \psi^0(L+it) + 2^{it}\Gamma(L+it) \frac{d \psi^0(L+it)}{dt} \right]_{t=0}
\end{eqnarray*}
That is equivalent to saying that
\begin{equation}
  E(\Lambda^2) = \left[ \psi^0(L)+\ln(2) \right]^2 + \psi^1(L)
\end{equation}
%since $\frac{d\psi^0(x)}{dx}=\psi^1(x)$ then
%$E(X^2) = (\psi^0(L)+\ln(2))(\psi^0(L)+\ln(2)) + \psi^1(L)$.

Thus we can state that
\begin{equation}
var(\Lambda)=E(\Lambda^2)-E^2(\Lambda)=\psi^1(L)
\end{equation}

\subsection{Averages and Variances of POLSAR Covariance Matrix Determinant and Log-Determinant}

In this section, the expected value and variance value of these mixture of random variables are derived
\begin{eqnarray}
\chi^d_L &\sim& \prod_{i=0}^{d-1} \chi (2L-2i) \\
\Lambda^d_L &\sim& \sum_{i=0}^{d-1} \Lambda (2L-2i)
\end{eqnarray}
given the averages and variances of individual components.
\begin{eqnarray}
avg \left[ \chi(2L) \right]&=&2L \\
var \left[ \chi(2L) \right]&=&4L \\
avg \left[ \Lambda(2L) \right] &=& \psi^0(L) + \ln2 \\
var \left[ \Lambda(2L) \right] &=& \psi^1(L)
\end{eqnarray}

Making use of the mutual independence property of each component $X_i$,
  the variance and expectation of the summation and product of random variables can be written as:
\begin{eqnarray*}
avg \left( \sum^n_{i=1} X_i \right) &=& \sum^n_{i=1} avg(X_i), \\
var \left( \sum^n_{i=1} X_i \right) &=& \sum^n_{i=1} var(X_i), \\
avg \left( \prod^n_{i=1} X_i \right) &=& \prod^n_{i=1} avg(X_i), \\ 
var \left( \prod^n_{i=1} X_i \right) &=& \prod^n_{i=1} \left[ avg^2(X_i) + var(X_i) \right] - \prod^n_{i=1} avg^2(X_i).    
\end{eqnarray*}

Thus they can be rewritten more usefully as:
\begin{eqnarray*}
  avg \left[ \chi^d_L \right] &=& 2^d \cdot \prod^{d-1}_{i=0} (L-i), \\
  var \left[ \chi^d_L \right] &=& \prod^{d-1}_{i=0} 4(L-i)(L-i+1) - \prod^{d-1}_{i=0} 4(L-i)^2, \\
  avg \left[ \Lambda^d_L \right] &=& d \cdot \ln{2} + \sum^{d-1}_{i=0} \psi^0(L-i), \\
  var \left[ \Lambda^d_L \right] &=& \sum^{d-1}_{i=0} \psi^1(L-i)
\end{eqnarray*}

\section{Deriving the Characteristic Functions for the Consistent Measures of Distance}
\label{sec:appendix_b}

Given that the characteristic function (CF) of the elementary log-chi square distributions can be written as
\begin{eqnarray}
 CF_{\Lambda(2L)}(t) &=& 2^{it}\Gamma(L+it)/\Gamma(L) \nonumber
\end{eqnarray}
  then the CF for the following random variables,
  which are combinations of the above elementary random variables, can be derived
\begin{eqnarray*}
   \Lambda^d_L &\sim&  \sum^{d-1}_{i=0} \Lambda(2L-2i) \\
  \mathbb{L} &\sim&  \Lambda^d_L -d \cdot \ln(2L) \\
  \mathbb{D} &\sim& \mathbb{L} - d \cdot \ln{L} + \sum^{d-1}_{i=0} \psi^0(L-i) \\
  \mathbb{C} &\sim&  \sum^{d-1}_{i=0} \left[ \Lambda(2L-2i) - \Lambda(2L-2i) \right]
\end{eqnarray*}

Since we can state that
\begin{eqnarray*}
 CF_{\sum X_i}(t)   &=& \prod CF_{X_i}(t) \\
 CF_{x+k}(t) &=& e^{itk}CF_x(t)
\end{eqnarray*}
then we have:
%\begin{eqnarray}
%\end{eqnarray}
\begin{align}
  CF_{\Lambda^d_L}(t) &= \frac{2^{idt}}{\Gamma(L)^d} \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
   CF_{\mathbb{L}} &= \frac{1}{L^{idt} \Gamma(L)^d}  \prod^{d-1}_{j=0} \Gamma(L-j+it) \\
   CF_{\mathbb{D}} &= \frac{ 1 }{\Gamma(L)^d} \prod^{d-1}_{j=0} e^{idt \psi^0(L-j)} \Gamma(L-j+it)  
\end{align}

%The CF for the contrast random variable can also be written as
Also due to
\begin{eqnarray*}
  CF_{-\Lambda(2L)}(t) &=& 2^{-it}\frac{\Gamma(L-it)}{\Gamma(L)} \\ 
  \Delta(2L) &\sim& \Lambda(2L) - \Lambda(2L) \\
  \Gamma(L-it) \Gamma(L+it) &=&  \Gamma(2L)B(L-it,L+it) \\
   CF_{\Delta(2L)}(t) &=& \frac{\Gamma(2L)B(L-it,L+it)}{\Gamma^2(L)} 
\end{eqnarray*}
then we arrive at:
\begin{align}
  CF_{\mathbb{C}} &=&  \prod^{d-1}_{j=0} \frac{\Gamma(2L-2j)B(L-j-it,L-j+it)}{\Gamma^2(L-j)} 
\end{align}
with $\Gamma()$ and $B()$ denoting Gamma and Beta functions respectively.

\section{SAR intensity as a special case of POLSAR covariance matrix determinant}
\label{sec:appendix_sar_special_case_of_polsar}

In this appendix, the following results for SAR intensity $I$ are shown to be special cases of the results given in this paper for the determinant of the POLSAR covariance matrix $det|C_v|$.
Specifically, the following results extend from the authors previous work on single-look SAR \cite{Le_2013_TGRS_SAR_MSE}, i.e. $d=L=1$, which is considerd a special case. We can state the following:
\begin{eqnarray}
  I &\sim& \bar{I} \cdot pdf \left[ e^{-R} \right] \\
  \log_2{I} &\sim& \log_2{\bar{I}} + pdf \left[ 2^{D-2^D} \right] \\
  \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ e^{-R} \right]  \\
  \log_2{I} - \log_2{\bar{I}} = \mathbb{D} &\sim& pdf \left[ 2^De^{-2^D}\ln2 \right]\\
  \log_2{I_1} - \log_2{I_2} = \mathbb{C} &\sim& pdf \left[ \frac{2^c}{(1+2^c)^2} \ln2 \right] \\
  avg(\mathbb{D}) &=& -\gamma / \ln{2} \\
  var(\mathbb{D}) &=& \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  mse(\mathbb{D}) &=& \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{eqnarray}
but also the following well-known results are considered for multi-look SAR, i.e. $d=1,L>1$:
  \begin{eqnarray}
I &\sim& pdf \left[ \frac{L^L I^{L-1} e^{-LI/\bar{I}}}{\Gamma(L) \bar{I}^L} \right] \\
N = \ln{I} &\sim& pdf \left[ \frac{L^L}{\Gamma(L)} e^{L(N-\bar{N})-Le^{N-\bar{N}}} \right]
  \end{eqnarray}
It will be shown that all of these results are special cases of the result derived previously and rewritten below:
\begin{eqnarray}
  |C_v| &\sim& \frac{|\Sigma_v|}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i)  \label{eqn:polsar_det_cov_dist} \\
  \ln{|C_v|} &\sim& \ln{|\Sigma_v|} + \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \label{eqn:polsar_log_det_cov_dist} 
\end{eqnarray}
\begin{eqnarray}
  \frac{|C_v|}{|\Sigma_v|} = \mathbb{R} &\sim& \frac{1}{(2L)^d} \prod^{d-1}_{i=0} \chi^2(2L-2i) \label{eqn:polsar_ratio_det_cov_dist} \\
  \ln{|C_v|} - \ln{|\Sigma_v|} = \mathbb{D} &\sim& \sum^{d-1}_{i=0} \Lambda(2L-2i) - d \cdot \ln{2L} \label{eqn:polsar_dispersion_log_det_cov_dist} \\ 
  \ln{|C_{1v}|} - \ln{|C_{2v}|} = \mathbb{C} &\sim& \sum^{d-1}_{i=0} \Delta(2L-2i)
\end{eqnarray}
\begin{eqnarray}
  avg(\mathbb{D}) &=& \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \label{eqn:polsar_dispersion_averages} \\
  var(\mathbb{D}) &=& \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_variance} \\
  mse(\mathbb{D}) &=& \left[ \sum^{d-1}_{i=0} \psi^0(L-i) - d \cdot \ln{L} \right]^2 +  \sum^{d-1}_{i=0} \psi^1(L-i) \label{eqn:polsar_dispersion_mse}
\end{eqnarray}

This appendix also derives new results for multi-look SAR data,
  which can be thought of 
    either as extensions of the corresponding single-look SAR results
    or as simple cases of the POLSAR results presented above.
They are:
  \begin{eqnarray}
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& \frac{1}{2L} \chi^2(2L) \\
    \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& \Lambda(2L) - \ln{2L} \\
    \ln{I_1} - \ln{I_2} = \mathbb{C} &\sim& \Delta(2L) \\
    avg(\mathbb{D}) &=& \psi^0(L) - \ln{L} \\
    var(\mathbb{D}) &=& \psi^1(L) \\
    mse(\mathbb{D}) &=& \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
  \end{eqnarray}

The derivation process detailed below consists of two-phases.
The first phase collapses the generic multi-dimensional POLSAR results into the classical one-dimensional SAR domain.
Mathematically this means setting the dimensional number in POLSAR to  $d=1$
  and collapsing the POLSAR covariance matrix into the variance measure in SAR, which also equals the SAR intensity i.e. $|C_v|=I,|\Sigma_v|=\bar{I}$.

The output of the first phase, in the general case, is applicable to multi-look SAR data, where $d=1$ but $L>1$.
The second phase simplifies the multi-look results into single-look results, which will match those presented in our previous work \cite{Le_2013_TGRS_SAR_MSE}.
Mathematically, it means setting $L=1$ in the multi-look result
  and converting from the natural logarithmic domain used in this paper to the base-2 logarithm used in \cite{Le_2013_TGRS_SAR_MSE} (base-2 was chosen in the previous paper to simplify the computation).

\subsection{Original Domain: SAR Intensity and its ratio}

Setting $d=1$, $|C_v|=I$ and $|\Sigma_v|=\bar{I}$ into Eqns. \ref{eqn:polsar_det_cov_dist} and \ref{eqn:polsar_ratio_det_cov_dist}
we find that:
\begin{eqnarray*}
  I &\sim& \frac{\bar{I}}{2L} \chi^2(2L)  \\
  \frac{I}{\bar{I}} = \mathbb{R} &\sim& \frac{1}{2L}  \chi^2(2L)   
\end{eqnarray*}
Or in PDF forms, and applying the variable change theorem,:
\begin{eqnarray*}
    \frac{2L I}{\bar{I}} &\sim& pdf \left[ \frac{x^{L-1}e^{-x/2}}{2^L \Gamma(L)} \right] \\
  \frac{I}{\bar{I}} &\sim& pdf \left[ \frac{x^{L-1}e^{-x/2}}{2^L \Gamma(L)} \cdot dx/dt \right]_{x=2L \cdot t} \\
%    &\sim& pdf \left[ \frac{(2L)^{L-1} t^{L-1} e^{-Lt}}{2^L \Gamma(L)}  \cdot 2L \right] \\
    &\sim& pdf \left[ \frac{ L^{L} t^{L-1} e^{-Lt}}{ \Gamma(L)} \right] \\
  I &\sim& pdf \left[ \frac{ L^{L} t^{L-1} e^{-Lt}}{ \Gamma(L)} \cdot dt/dx \right]_{t=x/\bar{I}}  \\
%    &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L-1}\Gamma(L)} \cdot \frac{1}{\bar{I}} \right] \\
    &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \right]
\end{eqnarray*}

Thus we have the following results for multi-look SAR:
\begin{eqnarray}
    I &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{x}}}{ \bar{I}^{L}\Gamma(L)} \right] \label{eqn:multi_look_SAR_intensity_dist} \\
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \label{eqn:multi_look_SAR_ratio_dist} \right] 
\end{eqnarray}

Now setting $L=1$, these results become:
\begin{eqnarray}
    I &\sim& pdf \left[ \frac{ e^{x/\bar{I}}}{ \bar{I}} \right] \\
    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ e^{-x} \right] 
\end{eqnarray}
which is the same as stated in \cite{Le_2013_TGRS_SAR_MSE}, demonstrating that the previous work is a special case of the more generic POLSAR forms.

\subsection{Log-transformed domain: SAR log-intensity and the log-distance}

The result for multi-look SAR data written in the log-transformed domain can be derived from two different approaches.
The first is to follow a simplification method, where the results for log-transformed POLSAR data are simplified into log-transformed multi-look SAR results.

The second approach is to apply log-transformation to the results derived in the previous section. In this section, it is shown that both approaches would result in identical results.

Setting $d=1$, $|C_v|=I$ and $|\Sigma_v|=\bar{I}$ into Eqns. \ref{eqn:polsar_log_det_cov_dist} and \ref{eqn:polsar_dispersion_log_det_cov_dist}
we have
\begin{eqnarray*}
  \ln{I} &\sim& \ln{\bar{I}} + \Lambda(2L) - \ln{2L}  \\
  \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& \Lambda(2L) - \ln{2L} 
\end{eqnarray*}

Or in PDF form, and applying the variable change theorem we have:
\begin{eqnarray*}
  \ln{I} - \ln{\bar{I}} + \ln{2L} &\sim& pdf \left[ \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)} \right] \\
  \ln{I} - \ln{\bar{I}} &\sim& pdf \left[ \frac{e^{Lx-e^x/2}}{2^L \Gamma(L)} \cdot dx/dt \right]_{x=t+\ln{2L}} \\
%   &\sim& pdf \left[ \frac{e^{L(t+\ln{2L})-e^{t+\ln{2L}}/2}}{2^L \Gamma(L)}  \right] \\ 
   &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right] \\
  \ln{I} &\sim&  pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)} \cdot dt/dx \right]_{t=x-\ln{\bar{I}}} \\
 &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] 
\end{eqnarray*}
with $\bar{N} = \ln{\bar{I}}$. Thus the first approach arrives at
\begin{eqnarray}
   \ln{I} = \mathbb{N} &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] \\
   \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right]  
\end{eqnarray}

In the second approach, log-transformation is applied on previous results for multi-look SAR intensity and its ratio in the original domain (Eqns. \ref{eqn:multi_look_SAR_ratio_dist} and \ref{eqn:multi_look_SAR_intensity_dist}).
This also arrives at the same results shown above, however the detailed working is omitted for brevity.

%\begin{eqnarray*}
%    I &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{x}}}{ \bar{I}^{L}\Gamma(L)} \right] \\
%    \frac{I}{\bar{I}} = \mathbb{R} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \right] 
%\end{eqnarray*}
%Thus
%\begin{eqnarray*}
%  \ln{I} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \right]_{x=e^t} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{t(L-1)} e^{-Le^t/\bar{I}}}{ \bar{I}^{L}\Gamma(L)} \cdot e^t \right]_{\bar{I}=e^{\bar{N}}} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{L(t-\bar{N})} e^{-Le^{t-\bar{N}}}}{ \Gamma(L)}  \right] \\
%  \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& pdf \left[ \frac{ L^{L} x^{L-1} e^{-Lx}}{ \Gamma(L)} \cdot dx/dt \right]_{x=e^t} \\
%      &\sim& pdf \left[ \frac{ L^{L} e^{t(L-1)} e^{-Le^t}}{ \Gamma(L)} \cdot e^t \right] \\ 
%      &\sim& pdf \left[ \frac{ L^{L} e^{tL-Le^t} }{ \Gamma(L)}  \right] 
%\end{eqnarray*}
%
%Thus the second approach also arrives at
%\begin{eqnarray}
%   \ln{I} = \mathbb{N} &\sim&  pdf \left[ \frac{L^Le^{L(x-\bar{N})-Le^{x-\bar{N}}}}{ \Gamma(L)} \right] \\
%   \ln{I} - \ln{\bar{I}} = \mathbb{D} &\sim& pdf \left[ \frac{L^Le^{Lx-Le^x}}{ \Gamma(L)}  \right]  
%\end{eqnarray}

To compute summary statistics for the multi-look SAR dispersion,
  set $d=1$ into Eqns. \ref{eqn:polsar_dispersion_mse}, \ref{eqn:polsar_dispersion_averages} and \ref{eqn:polsar_dispersion_variance}
we have:
  \begin{eqnarray*}
    avg(\mathbb{L}) &=& \psi^0(L) - \ln{L} \\
    var(\mathbb{L}) &=& \psi^1(L) \\
    mse(\mathbb{L}) &=& \left[ \psi^0(L) - \ln{L} \right]^2 + \psi^1(L)
\end{eqnarray*}

This completes the first phase of the derivation process.
The second phase of simplification involves setting $L=1$ into the above results for multi-look SAR data,
  and converting natural logarithm into base-2 logarithm.
First, setting $L=1$ makes the above results become
\begin{eqnarray*}
   \ln{I} = \mathbb{N} &\sim&  pdf \left[ e^{(x-\bar{N})-e^{x-\bar{N}}} \right] \\
   \ln{I} - \ln{\bar{I}} = \mathbb{L} &\sim& pdf \left[ e^{x-e^x}  \right] \\ 
    avg(\mathbb{L}) &=& \psi^0(1) = -\gamma \\
    var(\mathbb{L}) &=& \psi^1(1) = \pi^2 / 6 \\  
    mse(\mathbb{L}) &=& \left[ \psi^0(1) \right]^2 + \psi^1(1) = \gamma^2 + \pi^2 / 6
\end{eqnarray*}
with $\gamma$ denoting the Euler-Mascharoni constant.
Then to convert to base-2 logarithm from natural logarithmic transformation,
  we again use the variable change theorem.
  That is:
  \begin{eqnarray*}
   \log_2{I}  = \mathbb{N}_2    &\sim&  pdf \left[ e^{(x-\bar{N})-e^{x-\bar{N}}} \cdot dx/dt \right]_{x=t\cdot \ln{2}} \\
   \mathbb{N} / \ln{2} = \mathbb{N}_2 &\sim&  pdf \left[ e^{(t\cdot \ln{2}-\bar{N})-e^{t\cdot \ln{2}-\bar{N}}} \ln{2} \right]_{\bar{N}_2 = \bar{N} \cdot \ln{2}} \\
       &\sim&  pdf \left[ 2^{t-\bar{N}_2}e^{2^{t-\bar{N}_2}} \ln{2} \right] 
  \end{eqnarray*}
\begin{eqnarray*}
   \log_2{I} - \log_2{\bar{I}} = \mathbb{L} / \ln{2} = \mathbb{L}_2 &\sim& pdf \left[ e^{x-e^x}  \right]_{x=t \cdot \ln{2}} \\  
%       &\sim& pdf \left[ e^{t \cdot \ln{2}-e^{t \cdot \ln{2}}} \ln{2}  \right] \\
       &\sim& pdf \left[ 2^t e^{2^t} \ln{2}  \right] 
\end{eqnarray*}
\begin{eqnarray*}
  avg(\mathbb{L}_2) &=& avg(\mathbb{L})/ \ln{2} = -\gamma / \ln{2} \\
  var(\mathbb{L}_2) &=& var(\mathbb{L})/ \ln^2{2} = \frac{\pi^2}{6} \frac{1}{ \ln^2{2}} \\
  mse(\mathbb{L}_2) &=& mse(\mathbb{L})/ \ln^2{2} = \frac{1}{\ln^2{2}}( \gamma^2 + \pi^2/6 ) = 4.1161 
\end{eqnarray*}

\subsection{Deriving the PDF for SAR dispersion and contrast}

The PDF for SAR dispersion can be easily derived from
  the PDF for the log-distance given above as:
  \begin{equation}
   \ln{I} - avg(\ln{I}) =  \mathbb{D} \sim pdf \left[ \frac{e^{L[x+\psi^0(L)]-Le^{x+\psi^0(L)-\ln{L}}}}{\Gamma(L)} \right]
  \end{equation}
due to $d=1$ and
\begin{eqnarray*}
  \mathbb{D} &\sim& \mathbb{L} - avg(\mathbb{L}) \\
  avg(\mathbb{L}) &=& \psi^0(L) - \ln{L} \\
  \mathbb{L} &\sim& pdf \left[ \frac{L^Le^{Lt-Le^t}}{ \Gamma(L)}  \right]
\end{eqnarray*}

Setting $L=1$ for Single-Look SAR we have
\begin{equation}
  \mathbb{D} \sim pdf \left[ e^{x-\gamma-e^{x-\gamma}} \right]
\end{equation}
due to: $\psi^0(1)=-\gamma$ and $\Gamma(1)=1$
with $\gamma$ being the Euler Mascheroni constant (which equals $0.5772$). 
In base-2 logarithm domain, invoking the variable change theorem:
\begin{eqnarray*}
  \mathbb{D}_2 &=& \log_2{I} - avg(\log_2{I}) = \mathbb{D}/\ln{2} \\
  \mathbb{D}_2 &\sim& pdf \left[ e^{x-\gamma-e^{x-\gamma}} \cdot \frac{dx}{dt} \right]_{x=t \cdot \ln2}
\end{eqnarray*}
Thus we have
\begin{equation}
  \mathbb{D}_2 \sim pdf \left[ e^{-(2^xe^{-\gamma})} (2^xe^{-\gamma}) \ln2 \right]
\end{equation}
which is consistent with the results found in our previous work \cite{Le_2013_TGRS_SAR_MSE}.

Setting $d=1$ into Eqn. for contrast results in
\begin{equation}
  \ln{I_1} - \ln{I_2} = \mathbb{C} \sim \Delta(2L)
\end{equation}
The characteristic function would then be
\begin{equation}
  CF_\mathbb{C} =  \frac{\Gamma(2L) B(L-it,L+it)}{\Gamma(L)^2} 
\end{equation}
Thus the PDF can be written as
\begin{equation}
  \mathbb{C} \sim pdf \left[ \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{e^{Lx}}{(1+e^x)^{2L}} \right] \label{eqn:multi_look_SAR_contrast_pdf}
\end{equation}
due to
\begin{eqnarray*}
  CF_{\mathbb{C}}(x) &=& \frac{\Gamma(2L) }{\Gamma(L)^2} B(1/(1+e^x),L-it,L+it)  \\
       &=& \frac{\Gamma(2L) }{\Gamma(L)^2} \int^{1/(1+e^x)}_0 z^{L-it-1}(1-z)^{L+it-1} dz \\
  \frac{\partial }{\partial x} CF_{\mathbb{C}}(x) &=&  \frac{\partial CF_{\mathbb{C}}(x) }{\partial 1/(1+e^x)} \cdot \frac{\partial 1/(1+e^x)}{\partial x} \\
%       &=& \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{1}{(1+e^x)^{L-it-1}} \left( \frac{e^x}{1+e^x} \right)^{L+it-1} \frac{1}{(1+e^x)^2} e^x \\
        &=&  e^{itx} \frac{\Gamma(2L) }{\Gamma(L)^2} \frac{e^{Lx}}{(1+e^x)^{2L}}   
\end{eqnarray*}

Setting $L=1$ into Eqn. \ref{eqn:multi_look_SAR_contrast_pdf} 
we have the PDF for contrast of single-look SAR data:
\begin{equation}
  \mathbb{C} \sim pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \right]
\end{equation}

Converting to base-2 logarithm gives the following:
\begin{eqnarray*}
  \mathbb{C} / \ln{2} = \mathbb{C}_2 &\sim& pdf \left[ \frac{e^{x}}{(1+e^x)^{2}} \cdot dx/dt \right]_{x=t \cdot \ln{2}} \\
%     &\sim& pdf \left[ \ln{2} \frac{e^{t \cdot \ln{2}}}{(1+e^{t \cdot \ln{2}})^{2}}  \right] \\
     &\sim& pdf \left[ \ln{2} \frac{2^t}{(1+2^t)^{2}}  \right] 
\end{eqnarray*}
which is also consistent to the results shown in our previous work \cite{Le_2013_TGRS_SAR_MSE}.

% references section
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,article}

\end{document}
